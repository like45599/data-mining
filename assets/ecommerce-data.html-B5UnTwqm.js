import{_ as s,e as a,i as t,o as p}from"./app-CztZx2qC.js";const e={};function i(o,n){return p(),a("div",null,n[0]||(n[0]=[t(`<h1 id="e-commerce-user-data-cleaning-and-analysis" tabindex="-1"><a class="header-anchor" href="#e-commerce-user-data-cleaning-and-analysis"><span>E-commerce User Data Cleaning and Analysis</span></a></h1><div class="knowledge-card"><div class="knowledge-card__title"><span class="icon">ðŸ“š</span>Project Overview </div><div class="knowledge-card__content"><ul><li><strong>Difficulty</strong>: Entry-level</li><li><strong>Type</strong>: Data cleaning and preprocessing</li><li><strong>Skills</strong>: Missing value treatment, anomaly detection, data transformation, feature engineering</li><li><strong>Corresponding Knowledge Module</strong>: <a href="/en/core/preprocessing/data-presentation.html">Data Preprocessing</a></li></ul></div></div><h2 id="project-background" tabindex="-1"><a class="header-anchor" href="#project-background"><span>Project Background</span></a></h2><p>E-commerce platforms generate massive amounts of user behavior data daily, including activities such as browsing, searching, adding to cart, and purchasing. This data is critical for understanding user behavior patterns, optimizing product recommendations, and improving conversion rates. However, raw data often contains missing values, outliers, and inconsistent formats, which need to be cleaned and preprocessed before further analysis.</p><p>In this project, we will process a dataset of user behavior from an e-commerce platform, performing data cleaning and preprocessing to prepare for subsequent user behavior analysis.</p><div class="knowledge-card"><div class="knowledge-card__title"><span class="icon">ðŸ’¡</span>Did You Know? </div><div class="knowledge-card__content"><p>Data scientists typically spend 60-70% of their time on data cleaning and preprocessing. High-quality data preprocessing not only improves model performance but also reduces errors and biases in subsequent analyses.</p></div></div><h2 id="dataset-introduction" tabindex="-1"><a class="header-anchor" href="#dataset-introduction"><span>Dataset Introduction</span></a></h2><p>The dataset used in this project contains one week of user behavior data from an e-commerce platform, consisting of 10,000 records with the following fields:</p><ul><li><strong>user_id</strong>: User ID</li><li><strong>session_id</strong>: Session ID</li><li><strong>timestamp</strong>: Activity timestamp</li><li><strong>page_url</strong>: URL of the visited page</li><li><strong>event_type</strong>: Event type (view, cart, purchase)</li><li><strong>product_id</strong>: Product ID</li><li><strong>category</strong>: Product category</li><li><strong>price</strong>: Product price</li><li><strong>user_agent</strong>: User browser information</li><li><strong>user_region</strong>: User region</li></ul><p>The dataset contains various data quality issues, including missing values, outliers, inconsistent formats, and duplicate records.</p><h2 id="project-objectives" tabindex="-1"><a class="header-anchor" href="#project-objectives"><span>Project Objectives</span></a></h2><ol><li>Identify and handle missing values in the dataset.</li><li>Detect and handle outliers and anomalies.</li><li>Standardize and transform data formats.</li><li>Create meaningful derived features.</li><li>Prepare a clean dataset for subsequent analysis.</li></ol><h2 id="implementation-steps" tabindex="-1"><a class="header-anchor" href="#implementation-steps"><span>Implementation Steps</span></a></h2><h3 id="step-1-data-loading-and-preliminary-exploration" tabindex="-1"><a class="header-anchor" href="#step-1-data-loading-and-preliminary-exploration"><span>Step 1: Data Loading and Preliminary Exploration</span></a></h3><p>First, we load the data and perform an initial exploration to understand its basic characteristics.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd</span>
<span class="line"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np</span>
<span class="line"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt</span>
<span class="line"><span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns</span>
<span class="line"></span>
<span class="line"><span class="token comment"># Load the data</span></span>
<span class="line">df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">&#39;ecommerce_data.csv&#39;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># View basic information about the data</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>describe<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Display the first few rows</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Check for missing values</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Check for duplicate records</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Number of duplicate records: </span><span class="token interpolation"><span class="token punctuation">{</span>df<span class="token punctuation">.</span>duplicated<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="step-2-handling-missing-values" tabindex="-1"><a class="header-anchor" href="#step-2-handling-missing-values"><span>Step 2: Handling Missing Values</span></a></h3><p>Based on our preliminary exploration, we found missing values in the dataset that need to be handled with appropriate strategies.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># Check the percentage of missing values for each column</span></span>
<span class="line">missing_percentage <span class="token operator">=</span> df<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">100</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>missing_percentage<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Handle missing product prices â€“ fill with the median price of products in the same category</span></span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;price&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token string">&#39;category&#39;</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">&#39;price&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>transform<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>x<span class="token punctuation">.</span>median<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Handle missing user regions â€“ fill with the mode</span></span>
<span class="line">most_common_region <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">&#39;user_region&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;user_region&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">&#39;user_region&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>most_common_region<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Handle missing product categories â€“ infer from product_id</span></span>
<span class="line"><span class="token comment"># Assume we have a product mapping dictionary</span></span>
<span class="line">product_category_map <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span>  <span class="token comment"># In a real project, this mapping needs to be constructed</span></span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;category&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> row<span class="token punctuation">:</span> product_category_map<span class="token punctuation">.</span>get<span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token string">&#39;product_id&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> row<span class="token punctuation">[</span><span class="token string">&#39;category&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span> </span>
<span class="line">                         <span class="token keyword">if</span> pd<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token string">&#39;category&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">else</span> row<span class="token punctuation">[</span><span class="token string">&#39;category&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Drop records missing critical information</span></span>
<span class="line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>subset<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&#39;user_id&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;session_id&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;timestamp&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;event_type&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Check the missing values after processing</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="step-3-detecting-and-handling-outliers" tabindex="-1"><a class="header-anchor" href="#step-3-detecting-and-handling-outliers"><span>Step 3: Detecting and Handling Outliers</span></a></h3><p>Next, we detect and handle outliers in the dataset.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># Check the distribution of prices</span></span>
<span class="line">plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">sns<span class="token punctuation">.</span>boxplot<span class="token punctuation">(</span>x<span class="token operator">=</span>df<span class="token punctuation">[</span><span class="token string">&#39;price&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">&#39;Price Distribution&#39;</span><span class="token punctuation">)</span></span>
<span class="line">plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Detect price outliers using the IQR method</span></span>
<span class="line">Q1 <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">&#39;price&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>quantile<span class="token punctuation">(</span><span class="token number">0.25</span><span class="token punctuation">)</span></span>
<span class="line">Q3 <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">&#39;price&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>quantile<span class="token punctuation">(</span><span class="token number">0.75</span><span class="token punctuation">)</span></span>
<span class="line">IQR <span class="token operator">=</span> Q3 <span class="token operator">-</span> Q1</span>
<span class="line">lower_bound <span class="token operator">=</span> Q1 <span class="token operator">-</span> <span class="token number">1.5</span> <span class="token operator">*</span> IQR</span>
<span class="line">upper_bound <span class="token operator">=</span> Q3 <span class="token operator">+</span> <span class="token number">1.5</span> <span class="token operator">*</span> IQR</span>
<span class="line"></span>
<span class="line"><span class="token comment"># Identify outliers</span></span>
<span class="line">price_outliers <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">&#39;price&#39;</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> lower_bound<span class="token punctuation">)</span> <span class="token operator">|</span> <span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">&#39;price&#39;</span><span class="token punctuation">]</span> <span class="token operator">&gt;</span> upper_bound<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Number of price outliers: </span><span class="token interpolation"><span class="token punctuation">{</span>price_outliers<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Handle price outliers â€“ clip extreme values to a reasonable range</span></span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;price_cleaned&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">&#39;price&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>clip<span class="token punctuation">(</span>lower_bound<span class="token punctuation">,</span> upper_bound<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Validate timestamps</span></span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;timestamp&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> pd<span class="token punctuation">.</span>to_datetime<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">&#39;timestamp&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> errors<span class="token operator">=</span><span class="token string">&#39;coerce&#39;</span><span class="token punctuation">)</span></span>
<span class="line">invalid_timestamps <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">&#39;timestamp&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Number of invalid timestamps: </span><span class="token interpolation"><span class="token punctuation">{</span>invalid_timestamps<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Drop records with invalid timestamps</span></span>
<span class="line">df <span class="token operator">=</span> df<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>subset<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&#39;timestamp&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Check the validity of event types</span></span>
<span class="line">valid_event_types <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;view&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;cart&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;purchase&#39;</span><span class="token punctuation">]</span></span>
<span class="line">invalid_events <span class="token operator">=</span> <span class="token operator">~</span>df<span class="token punctuation">[</span><span class="token string">&#39;event_type&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isin<span class="token punctuation">(</span>valid_event_types<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Number of invalid event types: </span><span class="token interpolation"><span class="token punctuation">{</span>invalid_events<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Correct event types â€“ assume some rules for correction</span></span>
<span class="line">df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">&#39;event_type&#39;</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">&#39;add_to_cart&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;event_type&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&#39;cart&#39;</span></span>
<span class="line">df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">&#39;event_type&#39;</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">&#39;buy&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;event_type&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&#39;purchase&#39;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="step-4-data-standardization-and-format-conversion" tabindex="-1"><a class="header-anchor" href="#step-4-data-standardization-and-format-conversion"><span>Step 4: Data Standardization and Format Conversion</span></a></h3><p>To facilitate subsequent analysis, we standardize data formats.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># Standardize timestamp format</span></span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;date&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">&#39;timestamp&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dt<span class="token punctuation">.</span>date</span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;hour&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">&#39;timestamp&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dt<span class="token punctuation">.</span>hour</span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;day_of_week&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">&#39;timestamp&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dt<span class="token punctuation">.</span>day_name<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Extract page type from URL</span></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">extract_page_type</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">if</span> <span class="token string">&#39;product&#39;</span> <span class="token keyword">in</span> url<span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> <span class="token string">&#39;product_page&#39;</span></span>
<span class="line">    <span class="token keyword">elif</span> <span class="token string">&#39;category&#39;</span> <span class="token keyword">in</span> url<span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> <span class="token string">&#39;category_page&#39;</span></span>
<span class="line">    <span class="token keyword">elif</span> <span class="token string">&#39;search&#39;</span> <span class="token keyword">in</span> url<span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> <span class="token string">&#39;search_page&#39;</span></span>
<span class="line">    <span class="token keyword">elif</span> <span class="token string">&#39;cart&#39;</span> <span class="token keyword">in</span> url<span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> <span class="token string">&#39;cart_page&#39;</span></span>
<span class="line">    <span class="token keyword">elif</span> <span class="token string">&#39;checkout&#39;</span> <span class="token keyword">in</span> url<span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> <span class="token string">&#39;checkout_page&#39;</span></span>
<span class="line">    <span class="token keyword">else</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> <span class="token string">&#39;other&#39;</span></span>
<span class="line"></span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;page_type&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">&#39;page_url&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>extract_page_type<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Standardize product category</span></span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;category&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">&#39;category&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">str</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">str</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Extract device type from user_agent</span></span>
<span class="line"><span class="token keyword">def</span> <span class="token function">extract_device_type</span><span class="token punctuation">(</span>user_agent<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">if</span> pd<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span>user_agent<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> <span class="token string">&#39;unknown&#39;</span></span>
<span class="line">    user_agent <span class="token operator">=</span> user_agent<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">if</span> <span class="token string">&#39;mobile&#39;</span> <span class="token keyword">in</span> user_agent <span class="token keyword">or</span> <span class="token string">&#39;android&#39;</span> <span class="token keyword">in</span> user_agent <span class="token keyword">or</span> <span class="token string">&#39;iphone&#39;</span> <span class="token keyword">in</span> user_agent<span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> <span class="token string">&#39;mobile&#39;</span></span>
<span class="line">    <span class="token keyword">elif</span> <span class="token string">&#39;tablet&#39;</span> <span class="token keyword">in</span> user_agent <span class="token keyword">or</span> <span class="token string">&#39;ipad&#39;</span> <span class="token keyword">in</span> user_agent<span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> <span class="token string">&#39;tablet&#39;</span></span>
<span class="line">    <span class="token keyword">else</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> <span class="token string">&#39;desktop&#39;</span></span>
<span class="line"></span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;device_type&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">&#39;user_agent&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>extract_device_type<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="step-5-creating-derived-features" tabindex="-1"><a class="header-anchor" href="#step-5-creating-derived-features"><span>Step 5: Creating Derived Features</span></a></h3><p>To enhance the analytical value of the data, we create several derived features.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># Calculate session duration</span></span>
<span class="line">session_start <span class="token operator">=</span> df<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token string">&#39;session_id&#39;</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">&#39;timestamp&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">session_end <span class="token operator">=</span> df<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token string">&#39;session_id&#39;</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">&#39;timestamp&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">session_duration <span class="token operator">=</span> <span class="token punctuation">(</span>session_end <span class="token operator">-</span> session_start<span class="token punctuation">)</span><span class="token punctuation">.</span>dt<span class="token punctuation">.</span>total_seconds<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">60</span>  <span class="token comment"># Convert to minutes</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Merge session duration into the original dataframe</span></span>
<span class="line">session_duration_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&#39;session_duration&#39;</span><span class="token punctuation">:</span> session_duration<span class="token punctuation">}</span><span class="token punctuation">)</span></span>
<span class="line">session_duration_df<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line">df <span class="token operator">=</span> pd<span class="token punctuation">.</span>merge<span class="token punctuation">(</span>df<span class="token punctuation">,</span> session_duration_df<span class="token punctuation">,</span> on<span class="token operator">=</span><span class="token string">&#39;session_id&#39;</span><span class="token punctuation">,</span> how<span class="token operator">=</span><span class="token string">&#39;left&#39;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Count the number of activities per session for each event type</span></span>
<span class="line">activity_count <span class="token operator">=</span> df<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">&#39;session_id&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;event_type&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unstack<span class="token punctuation">(</span>fill_value<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line">activity_count<span class="token punctuation">.</span>columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f&#39;</span><span class="token interpolation"><span class="token punctuation">{</span>col<span class="token punctuation">}</span></span><span class="token string">_count&#39;</span></span> <span class="token keyword">for</span> col <span class="token keyword">in</span> activity_count<span class="token punctuation">.</span>columns<span class="token punctuation">]</span></span>
<span class="line">activity_count<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line">df <span class="token operator">=</span> pd<span class="token punctuation">.</span>merge<span class="token punctuation">(</span>df<span class="token punctuation">,</span> activity_count<span class="token punctuation">,</span> on<span class="token operator">=</span><span class="token string">&#39;session_id&#39;</span><span class="token punctuation">,</span> how<span class="token operator">=</span><span class="token string">&#39;left&#39;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Create a purchase flag</span></span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;has_purchase&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">&#39;session_id&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isin<span class="token punctuation">(</span>df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">&#39;event_type&#39;</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">&#39;purchase&#39;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">&#39;session_id&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Calculate price ranges</span></span>
<span class="line">price_bins <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">&#39;inf&#39;</span><span class="token punctuation">)</span><span class="token punctuation">]</span></span>
<span class="line">price_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;very_low&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;low&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;medium&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;high&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;very_high&#39;</span><span class="token punctuation">]</span></span>
<span class="line">df<span class="token punctuation">[</span><span class="token string">&#39;price_range&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> pd<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">&#39;price_cleaned&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bins<span class="token operator">=</span>price_bins<span class="token punctuation">,</span> labels<span class="token operator">=</span>price_labels<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="step-6-data-validation-and-export" tabindex="-1"><a class="header-anchor" href="#step-6-data-validation-and-export"><span>Step 6: Data Validation and Export</span></a></h3><p>Finally, we validate the cleaned data and export it for further analysis.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py"><pre><code><span class="line"><span class="token comment"># Check data quality</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Shape of cleaned data:&quot;</span><span class="token punctuation">,</span> df<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Missing values:&quot;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Check data consistency</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Event type distribution:&quot;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">&#39;event_type&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Device type distribution:&quot;</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">&#39;device_type&#39;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Export the cleaned data</span></span>
<span class="line">df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">&#39;ecommerce_data_cleaned.csv&#39;</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># Create a summary for further analysis</span></span>
<span class="line">session_summary <span class="token operator">=</span> df<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token string">&#39;session_id&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>agg<span class="token punctuation">(</span><span class="token punctuation">{</span></span>
<span class="line">    <span class="token string">&#39;user_id&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;first&#39;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&#39;date&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;first&#39;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&#39;device_type&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;first&#39;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&#39;view_count&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;first&#39;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&#39;cart_count&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;first&#39;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&#39;purchase_count&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;first&#39;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&#39;session_duration&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;first&#39;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&#39;has_purchase&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;first&#39;</span></span>
<span class="line"><span class="token punctuation">}</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">session_summary<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">&#39;session_summary.csv&#39;</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="results-analysis" tabindex="-1"><a class="header-anchor" href="#results-analysis"><span>Results Analysis</span></a></h2><p>Through the data cleaning and preprocessing process, we have addressed the following data quality issues:</p><ol><li><strong>Missing Value Handling</strong>: Filled missing prices, user regions, and product categories, and dropped records missing critical information.</li><li><strong>Outlier Handling</strong>: Detected and handled price outliers, and corrected invalid timestamps and event types.</li><li><strong>Data Standardization</strong>: Unified time formats, standardized product categories, and extracted page types and device types.</li><li><strong>Feature Engineering</strong>: Created derived features such as session duration, activity counts, purchase flag, and price range.</li></ol><p>The cleaned dataset is now more complete, consistent, and structured, providing a solid foundation for subsequent user behavior analysis.</p><h2 id="advanced-challenges" tabindex="-1"><a class="header-anchor" href="#advanced-challenges"><span>Advanced Challenges</span></a></h2><p>If you have completed the basic tasks, consider trying the following advanced challenges:</p><ol><li><strong>Advanced Missing Value Imputation</strong>: Use machine learning models to predict missing values.</li><li><strong>User Behavior Sequence Analysis</strong>: Analyze the sequence of user actions within a session and their conversion paths.</li><li><strong>Anomaly Detection Algorithms</strong>: Apply algorithms like isolation forest to automatically detect multi-dimensional anomalies.</li><li><strong>Feature Importance Analysis</strong>: Evaluate the predictive power of different features on purchase behavior.</li><li><strong>Data Visualization</strong>: Create interactive dashboards to display insights from the cleaned data.</li></ol><h2 id="summary-and-reflection" tabindex="-1"><a class="header-anchor" href="#summary-and-reflection"><span>Summary and Reflection</span></a></h2><p>Through this project, we learned how to address common data quality issues in e-commerce user data and prepare it for further analysis. Data preprocessing is fundamental to data analysis and mining, and high-quality data is crucial for drawing reliable conclusions.</p><p>In practical applications, this kind of data cleaning work helps e-commerce platforms better understand user behavior, optimize user experience, and improve conversion rates and sales. For example, analyzing differences in conversion rates across device types can inform targeted improvements to mobile or desktop interfaces.</p><h3 id="reflection-questions" tabindex="-1"><a class="header-anchor" href="#reflection-questions"><span>Reflection Questions</span></a></h3><ol><li>What factors should be considered when choosing an appropriate strategy for handling missing values?</li><li>Should outliers always be removed or corrected? Under what circumstances might outliers contain valuable information?</li><li>How can the effectiveness of data cleaning and preprocessing be evaluated? What metrics can measure the improvement in data quality?</li></ol><div class="practice-link"><a href="/en/projects/preprocessing/medical-missing-values.html" class="button">Next Project: Handling Missing Values in Medical Data</a></div>`,44)]))}const l=s(e,[["render",i],["__file","ecommerce-data.html.vue"]]),u=JSON.parse('{"path":"/en/projects/preprocessing/ecommerce-data.html","title":"E-commerce User Data Cleaning and Analysis","lang":"en-US","frontmatter":{},"headers":[{"level":2,"title":"Project Background","slug":"project-background","link":"#project-background","children":[]},{"level":2,"title":"Dataset Introduction","slug":"dataset-introduction","link":"#dataset-introduction","children":[]},{"level":2,"title":"Project Objectives","slug":"project-objectives","link":"#project-objectives","children":[]},{"level":2,"title":"Implementation Steps","slug":"implementation-steps","link":"#implementation-steps","children":[{"level":3,"title":"Step 1: Data Loading and Preliminary Exploration","slug":"step-1-data-loading-and-preliminary-exploration","link":"#step-1-data-loading-and-preliminary-exploration","children":[]},{"level":3,"title":"Step 2: Handling Missing Values","slug":"step-2-handling-missing-values","link":"#step-2-handling-missing-values","children":[]},{"level":3,"title":"Step 3: Detecting and Handling Outliers","slug":"step-3-detecting-and-handling-outliers","link":"#step-3-detecting-and-handling-outliers","children":[]},{"level":3,"title":"Step 4: Data Standardization and Format Conversion","slug":"step-4-data-standardization-and-format-conversion","link":"#step-4-data-standardization-and-format-conversion","children":[]},{"level":3,"title":"Step 5: Creating Derived Features","slug":"step-5-creating-derived-features","link":"#step-5-creating-derived-features","children":[]},{"level":3,"title":"Step 6: Data Validation and Export","slug":"step-6-data-validation-and-export","link":"#step-6-data-validation-and-export","children":[]}]},{"level":2,"title":"Results Analysis","slug":"results-analysis","link":"#results-analysis","children":[]},{"level":2,"title":"Advanced Challenges","slug":"advanced-challenges","link":"#advanced-challenges","children":[]},{"level":2,"title":"Summary and Reflection","slug":"summary-and-reflection","link":"#summary-and-reflection","children":[{"level":3,"title":"Reflection Questions","slug":"reflection-questions","link":"#reflection-questions","children":[]}]}],"git":{},"filePathRelative":"en/projects/preprocessing/ecommerce-data.md"}');export{l as comp,u as data};
