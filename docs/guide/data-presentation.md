# æ•°æ®è¡¨ç¤ºæ–¹æ³•

<div class="knowledge-card">
  <div class="knowledge-card__title">
    <span class="icon">ğŸ“š</span>æœ¬èŠ‚è¦ç‚¹
  </div>
  <div class="knowledge-card__content">
    <ul>
      <li>ç†è§£ä¸åŒæ•°æ®ç±»å‹çš„ç‰¹æ€§ä¸è¡¨ç¤ºæ–¹æ³•</li>
      <li>æŒæ¡å¸¸è§æ•°æ®ç»“æ„çš„ä½¿ç”¨åœºæ™¯</li>
      <li>å­¦ä¹ æ•°æ®è¡¨ç¤ºçš„æ ‡å‡†åŒ–å’Œå½’ä¸€åŒ–æ–¹æ³•</li>
      <li>äº†è§£ç‰¹å¾å·¥ç¨‹çš„åŸºç¡€æŠ€æœ¯</li>
    </ul>
  </div>
</div>

## æ•°æ®ç±»å‹ä»‹ç»

åœ¨æ•°æ®æŒ–æ˜ä¸­ï¼Œæ•°æ®ç±»å‹çš„æ­£ç¡®è¯†åˆ«å’Œå¤„ç†æ˜¯æˆåŠŸçš„å…³é”®ã€‚ä»¥ä¸‹æ˜¯å¸¸è§çš„æ•°æ®ç±»å‹ï¼š

### 1. æ•°å€¼å‹æ•°æ®

æ•°å€¼å‹æ•°æ®å¯ä»¥åˆ†ä¸ºè¿ç»­å‹å’Œç¦»æ•£å‹ï¼š

- **è¿ç»­æ•°å€¼**ï¼šå¯ä»¥å–ä»»æ„å®æ•°å€¼ï¼Œå¦‚æ¸©åº¦ï¼ˆ25.5Â°Cï¼‰ã€èº«é«˜ï¼ˆ175.2cmï¼‰
- **ç¦»æ•£æ•°å€¼**ï¼šåªèƒ½å–ç‰¹å®šçš„å€¼ï¼Œé€šå¸¸æ˜¯æ•´æ•°ï¼Œå¦‚å¹´é¾„ï¼ˆ18å²ï¼‰ã€æ•°é‡ï¼ˆ5ä¸ªï¼‰

**å¤„ç†å»ºè®®**ï¼šé€šå¸¸éœ€è¦è¿›è¡Œæ ‡å‡†åŒ–ä»¥æ¶ˆé™¤é‡çº²å½±å“ï¼Œå¸¸ç”¨æ–¹æ³•æœ‰ï¼š

- **Z-Scoreæ ‡å‡†åŒ–**ï¼š$z = \frac{x - \mu}{\sigma}$ï¼Œå…¶ä¸­$\mu$æ˜¯å‡å€¼ï¼Œ$\sigma$æ˜¯æ ‡å‡†å·®
- **Min-Maxå½’ä¸€åŒ–**ï¼š$x_{norm} = \frac{x - x_{min}}{x_{max} - x_{min}}$

**ä»£ç ç¤ºä¾‹**ï¼š

```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler
# åˆ›å»ºç¤ºä¾‹æ•°æ®
df = pd.DataFrame({'height': [165, 170, 175, 180, 185]})
# Z-Scoreæ ‡å‡†åŒ–
scaler = StandardScaler()
df['height_zscore'] = scaler.fit_transform(df[['height']])
# Min-Maxå½’ä¸€åŒ–
min_max_scaler = MinMaxScaler()
df['height_minmax'] = min_max_scaler.fit_transform(df[['height']])
print(df)
```


### 2. ç±»åˆ«å‹æ•°æ®

ç±»åˆ«å‹æ•°æ®è¡¨ç¤ºåˆ†ç±»ä¿¡æ¯ï¼Œåˆ†ä¸ºï¼š

- **åä¹‰å˜é‡**ï¼šæ²¡æœ‰å†…åœ¨é¡ºåºï¼Œå¦‚æ€§åˆ«ï¼ˆç”·/å¥³ï¼‰ã€é¢œè‰²ï¼ˆçº¢/è“/ç»¿ï¼‰
- **æœ‰åºå˜é‡**ï¼šæœ‰æ˜ç¡®é¡ºåºï¼Œå¦‚æ•™è‚²ç¨‹åº¦ï¼ˆå°å­¦/ä¸­å­¦/å¤§å­¦ï¼‰ã€æ»¡æ„åº¦ï¼ˆä½/ä¸­/é«˜ï¼‰

**å¤„ç†å»ºè®®**ï¼šé€šå¸¸éœ€è¦ç¼–ç è½¬æ¢ä¸ºæ•°å€¼ï¼Œå¸¸ç”¨æ–¹æ³•æœ‰ï¼š

- **One-Hotç¼–ç **ï¼šå°†ç±»åˆ«è½¬æ¢ä¸ºäºŒè¿›åˆ¶å‘é‡ï¼Œé€‚åˆåä¹‰å˜é‡
- **æ ‡ç­¾ç¼–ç **ï¼šå°†ç±»åˆ«æ˜ å°„ä¸ºæ•´æ•°ï¼Œé€‚åˆæœ‰åºå˜é‡
- **ç›®æ ‡ç¼–ç **ï¼šæ ¹æ®ç›®æ ‡å˜é‡çš„å‡å€¼æ›¿æ¢ç±»åˆ«ï¼Œé€‚åˆé«˜åŸºæ•°ç‰¹å¾

**ä»£ç ç¤ºä¾‹**ï¼š
```python
import pandas as pd
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
# åˆ›å»ºç¤ºä¾‹æ•°æ®
df = pd.DataFrame({
'color': ['red', 'blue', 'green', 'red', 'green'],
'size': ['small', 'medium', 'large', 'medium', 'small']
})
# One-Hotç¼–ç 
encoder = OneHotEncoder(sparse=False)
color_encoded = encoder.fit_transform(df[['color']])
color_df = pd.DataFrame(
color_encoded,
columns=[f'color_{c}' for c in encoder.categories_[0]]
)
# æ ‡ç­¾ç¼–ç 
label_encoder = LabelEncoder()
df['size_encoded'] = label_encoder.fit_transform(df['size'])
# åˆå¹¶ç»“æœ
result = pd.concat([df, color_df], axis=1)
print(result)
```


### 3. æ—¶é—´åºåˆ—æ•°æ®

æ—¶é—´åºåˆ—æ•°æ®éšæ—¶é—´å˜åŒ–ï¼Œå…·æœ‰æ—¶åºç‰¹æ€§ï¼š

- **æ—¶é—´æˆ³**ï¼šç‰¹å®šæ—¶é—´ç‚¹çš„è§‚æµ‹å€¼ï¼Œå¦‚è‚¡ç¥¨ä»·æ ¼ã€ä¼ æ„Ÿå™¨è¯»æ•°
- **æ—¶é—´åŒºé—´**ï¼šè·¨è¶Šä¸€æ®µæ—¶é—´çš„æ•°æ®ï¼Œå¦‚é€šè¯æ—¶é•¿ã€æ´»åŠ¨æŒç»­æ—¶é—´
- **å‘¨æœŸæ€§æ•°æ®**ï¼šå…·æœ‰é‡å¤æ¨¡å¼ï¼Œå¦‚å­£èŠ‚æ€§é”€å”®ã€æ¯æ—¥æ¸©åº¦å˜åŒ–

**å¤„ç†å»ºè®®**ï¼š

- æå–æ—¶é—´ç‰¹å¾ï¼ˆå¹´ã€æœˆã€æ—¥ã€å°æ—¶ã€å·¥ä½œæ—¥ç­‰ï¼‰
- æ»‘åŠ¨çª—å£èšåˆï¼ˆå‡å€¼ã€æœ€å¤§å€¼ã€æœ€å°å€¼ç­‰ï¼‰
- å¤„ç†å­£èŠ‚æ€§å’Œè¶‹åŠ¿

**ä»£ç ç¤ºä¾‹**ï¼š
```python
import pandas as pd
import numpy as np
åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®
date_rng = pd.date_range(start='2023-01-01', end='2023-01-31', freq='D')
df = pd.DataFrame(date_rng, columns=['date'])
df['value'] = np.random.randint(0, 100, size=len(date_rng))
æå–æ—¶é—´ç‰¹å¾
df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['day'] = df['date'].dt.day
df['dayofweek'] = df['date'].dt.dayofweek
df['is_weekend'] = df['dayofweek'].apply(lambda x: 1 if x >= 5 else 0)
# æ»‘åŠ¨çª—å£
df['rolling_mean_3d'] = df['value'].rolling(window=3).mean()
print(df.head())
```

<div class="knowledge-card">
  <div class="knowledge-card__title">
    <span class="icon">ğŸ’¡</span>ä½ çŸ¥é“å—ï¼Ÿ
  </div>
  <div class="knowledge-card__content">
    <p>åœ¨æ•°æ®ç§‘å­¦çš„æ—©æœŸï¼Œæ•°æ®è¡¨ç¤ºæ–¹æ³•ä¸»è¦æ˜¯åŸºäºå…³ç³»æ•°æ®åº“æ¨¡å‹ã€‚ç›´åˆ°1970å¹´ä»£ï¼ŒE.F. Coddæå‡ºäº†å…³ç³»æ¨¡å‹ï¼Œæ‰å¼€å§‹ç³»ç»Ÿåœ°æ€è€ƒæ•°æ®è¡¨ç¤ºé—®é¢˜ã€‚ç°ä»£æ•°æ®è¡¨ç¤ºæ–¹æ³•èåˆäº†ç»Ÿè®¡å­¦ã€è®¡ç®—æœºç§‘å­¦å’Œé¢†åŸŸçŸ¥è¯†ï¼Œå½¢æˆäº†ä¸°å¯Œçš„æ•°æ®é¢„å¤„ç†æŠ€æœ¯ä½“ç³»ã€‚</p>
  </div>
</div>

## æ•°æ®ç»“æ„ä¸å­˜å‚¨

### 1. è¡¨æ ¼å‹æ•°æ®

æœ€å¸¸è§çš„æ•°æ®å½¢å¼ï¼Œå¦‚ç”µå­è¡¨æ ¼å’Œå…³ç³»æ•°æ®åº“è¡¨ï¼š

- **è¡Œï¼ˆè®°å½•ï¼‰**ï¼šä»£è¡¨å•ä¸ªå®ä½“æˆ–å®ä¾‹
- **åˆ—ï¼ˆç‰¹å¾ï¼‰**ï¼šä»£è¡¨å®ä½“çš„å±æ€§æˆ–ç‰¹å¾
- **å•å…ƒæ ¼**ï¼šç‰¹å®šå®ä½“çš„ç‰¹å®šå±æ€§å€¼

**Pythonå®ç°**ï¼šé€šå¸¸ä½¿ç”¨Pandasçš„DataFrameè¿›è¡Œæ“ä½œ

```python
import pandas as pd
# åˆ›å»ºDataFrame
data = {
'name': ['Alice', 'Bob', 'Charlie'],
'age': [25, 30, 35],
'city': ['New York', 'Boston', 'Chicago']
}
df = pd.DataFrame(data)
print(df)
```


### 2. çŸ©é˜µå’Œå¼ é‡

æ”¯æŒé«˜çº§è®¡ç®—å’Œç®—æ³•å®ç°ï¼š

- **çŸ©é˜µ**ï¼šäºŒç»´æ•°ç»„ï¼Œå¦‚å›¾åƒæ•°æ®ã€è·ç¦»çŸ©é˜µ
- **å¼ é‡**ï¼šå¤šç»´æ•°ç»„ï¼Œå¸¸ç”¨äºæ·±åº¦å­¦ä¹ 

**Pythonå®ç°**ï¼šé€šå¸¸ä½¿ç”¨NumPyæˆ–PyTorch/TensorFlowçš„å¼ é‡
```python
import numpy as np
# åˆ›å»ºçŸ©é˜µ
matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
print("çŸ©é˜µ:\n", matrix)
# åˆ›å»º3Då¼ é‡
tensor = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])
print("å¼ é‡:\n", tensor)
```


### 3. å›¾ç»“æ„

è¡¨ç¤ºå®ä½“ä¹‹é—´çš„å…³ç³»ï¼š

- **èŠ‚ç‚¹ï¼ˆé¡¶ç‚¹ï¼‰**ï¼šä»£è¡¨å®ä½“
- **è¾¹**ï¼šä»£è¡¨å®ä½“é—´çš„å…³ç³»
- **æƒé‡**ï¼šå…³ç³»çš„å¼ºåº¦æˆ–é‡è¦æ€§

**Pythonå®ç°**ï¼šé€šå¸¸ä½¿ç”¨NetworkXæˆ–PyTorch Geometric
```python
import networkx as nx
import matplotlib.pyplot as plt
# åˆ›å»ºå›¾
G = nx.Graph()
G.add_edges_from([(1, 2), (1, 3), (2, 3), (2, 4), (3, 5)])
# å¯è§†åŒ–
plt.figure(figsize=(8, 6))
nx.draw(G, with_labels=True, node_color='lightblue',
node_size=500, font_size=15, font_weight='bold')
plt.title("ç®€å•çš„å›¾ç»“æ„")
plt.show()
```


## ç‰¹å¾è¡¨ç¤ºæŠ€æœ¯

### 1. ç‰¹å¾ç¼©æ”¾

ç¡®ä¿ä¸åŒç‰¹å¾çš„é‡çº²ä¸€è‡´ï¼Œé¿å…æŸäº›ç‰¹å¾ä¸»å¯¼æ¨¡å‹ï¼š
```python
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
# æ ‡å‡†åŒ–: å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1
std_scaler = StandardScaler()
X_std = std_scaler.fit_transform(X)
# å½’ä¸€åŒ–: ç¼©æ”¾åˆ°[0,1]åŒºé—´
minmax_scaler = MinMaxScaler()
X_minmax = minmax_scaler.fit_transform(X)
# ç¨³å¥ç¼©æ”¾: å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿ
robust_scaler = RobustScaler()
X_robust = robust_scaler.fit_transform(X)
```


### 2. ç‰¹å¾ç¼–ç 

å°†éæ•°å€¼ç‰¹å¾è½¬æ¢ä¸ºç®—æ³•å¯ç”¨çš„æ•°å€¼è¡¨ç¤ºï¼š
```python
from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder
# æ ‡ç­¾ç¼–ç : é€‚ç”¨äºæœ‰åºåˆ†ç±»å˜é‡
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)
# One-Hotç¼–ç : é€‚ç”¨äºæ— åºåˆ†ç±»å˜é‡
onehot_encoder = OneHotEncoder()
X_encoded = onehot_encoder.fit_transform(X_categorical)
# åºæ•°ç¼–ç : é€‚ç”¨äºæœ‰åºåˆ†ç±»å˜é‡ï¼Œä¿ç•™é¡ºåºä¿¡æ¯
ordinal_encoder = OrdinalEncoder(categories=[['ä½', 'ä¸­', 'é«˜']])
X_ordinal = ordinal_encoder.fit_transform(X_categorical)
```


### 3. ç‰¹å¾é€‰æ‹©

ä»åŸå§‹ç‰¹å¾é›†ä¸­é€‰æ‹©æœ€ç›¸å…³æˆ–æœ€é‡è¦çš„ç‰¹å¾ï¼š
```python
from sklearn.feature_selection import SelectKBest, f_classif, RFE
from sklearn.ensemble import RandomForestClassifier
# åŸºäºç»Ÿè®¡æ£€éªŒçš„ç‰¹å¾é€‰æ‹©
selector = SelectKBest(f_classif, k=5)
X_selected = selector.fit_transform(X, y)
#åŸºäºæ¨¡å‹çš„ç‰¹å¾é€‰æ‹©
model = RandomForestClassifier()
rfe = RFE(estimator=model, n_features_to_select=5)
X_rfe = rfe.fit_transform(X, y)
```


## å®è·µæŠ€å·§

### 1. æ•°æ®åŠ è½½ä¸æ£€æŸ¥

é¦–å…ˆè¦äº†è§£æ•°æ®çš„åŸºæœ¬æƒ…å†µï¼š
