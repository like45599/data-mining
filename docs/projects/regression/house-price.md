# æˆ¿ä»·é¢„æµ‹æ¨¡å‹

<div class="knowledge-card">
  <div class="knowledge-card__title">
    <span class="icon">ğŸ“š</span>é¡¹ç›®æ¦‚è¿°
  </div>
  <div class="knowledge-card__content">
    <ul>
      <li><strong>éš¾åº¦</strong>ï¼šä¸­çº§</li>
      <li><strong>ç±»å‹</strong>ï¼šå›å½’ - ä¸­çº§</li>
      <!-- <li><strong>é¢„è®¡æ—¶é—´</strong>ï¼š4-6å°æ—¶</li> -->
      <li><strong>æŠ€èƒ½ç‚¹</strong>ï¼šç‰¹å¾å·¥ç¨‹ã€å›å½’æ¨¡å‹ã€æ¨¡å‹è¯„ä¼°</li>
      <li><strong>å¯¹åº”çŸ¥è¯†æ¨¡å—</strong>ï¼š<a href="/core/regression/linear-regression.html">å›å½’åˆ†æ</a></li>
    </ul>
  </div>
</div>

## é¡¹ç›®èƒŒæ™¯

æˆ¿ä»·é¢„æµ‹æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„ç»å…¸é—®é¢˜ï¼Œå¯¹è´­æˆ¿è€…ã€é”€å”®è€…å’ŒæŠ•èµ„è€…éƒ½æœ‰é‡è¦æ„ä¹‰ã€‚é€šè¿‡åˆ†ææˆ¿å±‹ç‰¹å¾ï¼ˆå¦‚é¢ç§¯ã€ä½ç½®ã€æˆ¿é—´æ•°é‡ç­‰ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥æ„å»ºæ¨¡å‹æ¥é¢„æµ‹æˆ¿å±‹çš„å¸‚åœºä»·å€¼ã€‚

åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ³¢å£«é¡¿éƒŠåŒºçš„æˆ¿å±‹æ•°æ®é›†ï¼Œæ„å»ºä¸€ä¸ªæˆ¿ä»·é¢„æµ‹æ¨¡å‹ï¼Œæ¢ç´¢å½±å“æˆ¿ä»·çš„å…³é”®å› ç´ ã€‚

<div class="knowledge-card">
  <div class="knowledge-card__title">
    <span class="icon">ğŸ’¡</span>ä½ çŸ¥é“å—ï¼Ÿ
  </div>
  <div class="knowledge-card__content">
    <p>è®¸å¤šæˆ¿åœ°äº§ç½‘ç«™å¦‚Zillowéƒ½ä½¿ç”¨æœºå™¨å­¦ä¹ ç®—æ³•æä¾›è‡ªåŠ¨ä¼°ä»·æœåŠ¡ã€‚Zillowçš„"Zestimate"ä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹ä¸ºç¾å›½è¶…è¿‡1äº¿å¥—æˆ¿äº§æä¾›ä¼°ä»·ï¼Œå¹³å‡è¯¯å·®ç‡çº¦ä¸º2-3%ã€‚</p>
  </div>
</div>

## æ•°æ®é›†ä»‹ç»

æˆ‘ä»¬å°†ä½¿ç”¨æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«æ³¢å£«é¡¿éƒŠåŒº506ä¸ªç¤¾åŒºçš„æˆ¿å±‹ä¿¡æ¯çš„æ•°æ®é›†ã€‚æ¯ä¸ªæ ·æœ¬æœ‰13ä¸ªç‰¹å¾ï¼š

- CRIMï¼šåŸé•‡äººå‡çŠ¯ç½ªç‡
- ZNï¼šå åœ°é¢ç§¯è¶…è¿‡25,000å¹³æ–¹è‹±å°ºçš„ä½å®…ç”¨åœ°æ¯”ä¾‹
- INDUSï¼šæ¯ä¸ªåŸé•‡éé›¶å”®ä¸šåŠ¡çš„æ¯”ä¾‹
- CHASï¼šæŸ¥å°”æ–¯æ²³è™šæ‹Ÿå˜é‡ï¼ˆ1è¡¨ç¤ºé æ²³ï¼Œ0è¡¨ç¤ºä¸é æ²³ï¼‰
- NOXï¼šä¸€æ°§åŒ–æ°®æµ“åº¦
- RMï¼šæ¯æ ‹ä½å®…çš„å¹³å‡æˆ¿é—´æ•°
- AGEï¼š1940å¹´ä¹‹å‰å»ºæˆçš„è‡ªä½å•ä½æ¯”ä¾‹
- DISï¼šåˆ°æ³¢å£«é¡¿äº”ä¸ªå°±ä¸šä¸­å¿ƒçš„åŠ æƒè·ç¦»
- RADï¼šå¾„å‘å…¬è·¯çš„å¯è¾¾æ€§æŒ‡æ•°
- TAXï¼šæ¯10,000ç¾å…ƒçš„å…¨é¢è´¢äº§ç¨ç‡
- PTRATIOï¼šåŸé•‡å¸ˆç”Ÿæ¯”ä¾‹
- Bï¼š1000(Bk - 0.63)^2ï¼Œå…¶ä¸­Bkæ˜¯åŸé•‡é»‘äººæ¯”ä¾‹
- LSTATï¼šäººå£ä¸­åœ°ä½è¾ƒä½äººç¾¤çš„ç™¾åˆ†æ¯”

ç›®æ ‡å˜é‡æ˜¯MEDVï¼Œå³è‡ªä½æˆ¿çš„ä¸­ä½æ•°ä»·å€¼ï¼ˆå•ä½ï¼šåƒç¾å…ƒï¼‰ã€‚

## é¡¹ç›®ç›®æ ‡

1. æ„å»ºä¸€ä¸ªèƒ½å¤Ÿå‡†ç¡®é¢„æµ‹æˆ¿ä»·çš„å›å½’æ¨¡å‹
2. è¯†åˆ«å½±å“æˆ¿ä»·çš„å…³é”®ç‰¹å¾
3. æ¯”è¾ƒä¸åŒå›å½’ç®—æ³•çš„æ€§èƒ½
4. è¯„ä¼°æ¨¡å‹åœ¨ä¸åŒè¯„ä¼°æŒ‡æ ‡ä¸‹çš„è¡¨ç°

## å®æ–½æ­¥éª¤

### 1. æ•°æ®æ¢ç´¢ä¸å¯è§†åŒ–

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦äº†è§£æ•°æ®çš„åŸºæœ¬ç‰¹å¾å’Œåˆ†å¸ƒï¼š

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# åŠ è½½æ•°æ®
boston = load_boston()
df = pd.DataFrame(boston.data, columns=boston.feature_names)
df['MEDV'] = boston.target

# æŸ¥çœ‹æ•°æ®åŸºæœ¬ä¿¡æ¯
print(df.info())
print(df.describe())

# æ£€æŸ¥ç¼ºå¤±å€¼
print(df.isnull().sum())

# å¯è§†åŒ–ç›®æ ‡å˜é‡åˆ†å¸ƒ
plt.figure(figsize=(10, 6))
sns.histplot(df['MEDV'], kde=True)
plt.title('æˆ¿ä»·åˆ†å¸ƒ')
plt.xlabel('æˆ¿ä»·ï¼ˆåƒç¾å…ƒï¼‰')
plt.ylabel('é¢‘ç‡')
plt.show()

# æŸ¥çœ‹ç‰¹å¾ä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§
plt.figure(figsize=(12, 10))
correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ')
plt.show()

# æŸ¥çœ‹é‡è¦ç‰¹å¾ä¸æˆ¿ä»·çš„æ•£ç‚¹å›¾
important_features = ['RM', 'LSTAT', 'PTRATIO', 'DIS']
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes = axes.flatten()

for i, feature in enumerate(important_features):
    sns.scatterplot(x=feature, y='MEDV', data=df, ax=axes[i])
    axes[i].set_title(f'{feature} vs æˆ¿ä»·')

plt.tight_layout()
plt.show()
```

### 2. æ•°æ®é¢„å¤„ç†

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å‡†å¤‡æ•°æ®ç”¨äºæ¨¡å‹è®­ç»ƒï¼š

```python
# åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡å˜é‡
X = df.drop('MEDV', axis=1)
y = df['MEDV']

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ç‰¹å¾æ ‡å‡†åŒ–
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

### 3. æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°

æˆ‘ä»¬å°†å°è¯•å¤šç§å›å½’æ¨¡å‹ï¼Œå¹¶æ¯”è¾ƒå®ƒä»¬çš„æ€§èƒ½ï¼š

```python
# å®šä¹‰è¯„ä¼°å‡½æ•°
def evaluate_model(model, X_train, X_test, y_train, y_test):
    # è®­ç»ƒæ¨¡å‹
    model.fit(X_train, y_train)
    
    # é¢„æµ‹
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
    train_r2 = r2_score(y_train, y_train_pred)
    test_r2 = r2_score(y_test, y_test_pred)
    test_mae = mean_absolute_error(y_test, y_test_pred)
    
    print(f"è®­ç»ƒé›†RMSE: {train_rmse:.2f}")
    print(f"æµ‹è¯•é›†RMSE: {test_rmse:.2f}")
    print(f"è®­ç»ƒé›†RÂ²: {train_r2:.2f}")
    print(f"æµ‹è¯•é›†RÂ²: {test_r2:.2f}")
    print(f"æµ‹è¯•é›†MAE: {test_mae:.2f}")
    
    return model, y_test_pred

# çº¿æ€§å›å½’
print("çº¿æ€§å›å½’æ¨¡å‹:")
lr_model, lr_pred = evaluate_model(LinearRegression(), X_train_scaled, X_test_scaled, y_train, y_test)
print("\n")

# å²­å›å½’
print("å²­å›å½’æ¨¡å‹:")
ridge_model, ridge_pred = evaluate_model(Ridge(alpha=1.0), X_train_scaled, X_test_scaled, y_train, y_test)
print("\n")

# Lassoå›å½’
print("Lassoå›å½’æ¨¡å‹:")
lasso_model, lasso_pred = evaluate_model(Lasso(alpha=0.1), X_train_scaled, X_test_scaled, y_train, y_test)
print("\n")

# å†³ç­–æ ‘å›å½’
print("å†³ç­–æ ‘å›å½’æ¨¡å‹:")
dt_model, dt_pred = evaluate_model(DecisionTreeRegressor(max_depth=5), X_train, X_test, y_train, y_test)
print("\n")

# éšæœºæ£®æ—å›å½’
print("éšæœºæ£®æ—å›å½’æ¨¡å‹:")
rf_model, rf_pred = evaluate_model(RandomForestRegressor(n_estimators=100, max_depth=10), X_train, X_test, y_train, y_test)
```

### 4. ç‰¹å¾é‡è¦æ€§åˆ†æ

äº†è§£å“ªäº›ç‰¹å¾å¯¹æˆ¿ä»·å½±å“æœ€å¤§ï¼š

```python
# ä½¿ç”¨éšæœºæ£®æ—æ¨¡å‹åˆ†æç‰¹å¾é‡è¦æ€§
feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Importance': rf_model.feature_importances_
})
feature_importance = feature_importance.sort_values('Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance)
plt.title('ç‰¹å¾é‡è¦æ€§')
plt.tight_layout()
plt.show()
```

### 5. é¢„æµ‹å¯è§†åŒ–

å¯è§†åŒ–æ¨¡å‹é¢„æµ‹ç»“æœä¸å®é™…å€¼çš„å¯¹æ¯”ï¼š

```python
# å¯è§†åŒ–é¢„æµ‹ç»“æœ
plt.figure(figsize=(10, 6))
plt.scatter(y_test, rf_pred, alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel('å®é™…æˆ¿ä»·')
plt.ylabel('é¢„æµ‹æˆ¿ä»·')
plt.title('éšæœºæ£®æ—æ¨¡å‹ï¼šå®é™…æˆ¿ä»· vs é¢„æµ‹æˆ¿ä»·')
plt.tight_layout()
plt.show()

# æ®‹å·®åˆ†æ
residuals = y_test - rf_pred
plt.figure(figsize=(10, 6))
plt.scatter(rf_pred, residuals, alpha=0.7)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('é¢„æµ‹æˆ¿ä»·')
plt.ylabel('æ®‹å·®')
plt.title('æ®‹å·®åˆ†æ')
plt.tight_layout()
plt.show()
```

## è¿›é˜¶æŒ‘æˆ˜

å¦‚æœä½ å·²ç»å®Œæˆäº†åŸºæœ¬ä»»åŠ¡ï¼Œå¯ä»¥å°è¯•ä»¥ä¸‹è¿›é˜¶æŒ‘æˆ˜ï¼š

1. **ç‰¹å¾å·¥ç¨‹**ï¼šåˆ›å»ºæ–°ç‰¹å¾ï¼Œå¦‚æˆ¿é—´é¢ç§¯æ¯”ï¼ˆRM/LSTATï¼‰æˆ–äº¤äº’ç‰¹å¾
2. **è¶…å‚æ•°è°ƒä¼˜**ï¼šä½¿ç”¨ç½‘æ ¼æœç´¢æˆ–éšæœºæœç´¢ä¼˜åŒ–æ¨¡å‹å‚æ•°
3. **é›†æˆæ–¹æ³•**ï¼šå°è¯•ä½¿ç”¨å †å æˆ–æŠ•ç¥¨ç­‰é›†æˆæ–¹æ³•æé«˜é¢„æµ‹æ€§èƒ½
4. **éçº¿æ€§å˜æ¢**ï¼šå¯¹ç‰¹å¾æˆ–ç›®æ ‡å˜é‡åº”ç”¨å¯¹æ•°æˆ–å¤šé¡¹å¼å˜æ¢
5. **äº¤å‰éªŒè¯**ï¼šå®ç°kæŠ˜äº¤å‰éªŒè¯ï¼Œè·å¾—æ›´ç¨³å¥çš„æ¨¡å‹è¯„ä¼°

## å°ç»“ä¸åæ€

é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼Œæˆ‘ä»¬å­¦ä¹ äº†å¦‚ä½•æ„å»ºæˆ¿ä»·é¢„æµ‹æ¨¡å‹ï¼Œä»æ•°æ®æ¢ç´¢åˆ°æ¨¡å‹è¯„ä¼°çš„å®Œæ•´æµç¨‹ã€‚æˆ‘ä»¬å‘ç°æˆ¿é—´æ•°é‡ã€ä½æ”¶å…¥äººå£æ¯”ä¾‹å’Œå¸ˆç”Ÿæ¯”ç­‰å› ç´ å¯¹æˆ¿ä»·æœ‰æ˜¾è‘—å½±å“ã€‚

åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ¿ä»·é¢„æµ‹æ¨¡å‹å¯ä»¥å¸®åŠ©è´­æˆ¿è€…è¯„ä¼°æˆ¿å±‹çš„åˆç†ä»·æ ¼ï¼Œå¸®åŠ©é”€å”®è€…åˆ¶å®šåˆé€‚çš„å®šä»·ç­–ç•¥ï¼Œä¹Ÿå¯ä»¥å¸®åŠ©å¼€å‘å•†è¯†åˆ«æœ‰æ½œåŠ›çš„åŒºåŸŸã€‚

### æ€è€ƒé—®é¢˜

1. é™¤äº†æˆ‘ä»¬ä½¿ç”¨çš„ç‰¹å¾å¤–ï¼Œè¿˜æœ‰å“ªäº›å› ç´ å¯èƒ½å½±å“æˆ¿ä»·ï¼Ÿå¦‚ä½•è·å–è¿™äº›æ•°æ®ï¼Ÿ
2. æˆ‘ä»¬çš„æ¨¡å‹åœ¨å“ªäº›ç±»å‹çš„æˆ¿å±‹ä¸Šé¢„æµ‹æ•ˆæœè¾ƒå·®ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ
3. å¦‚ä½•å°†è¿™ä¸ªæ¨¡å‹åº”ç”¨åˆ°å…¶ä»–åŸå¸‚ï¼Ÿéœ€è¦è€ƒè™‘å“ªäº›å› ç´ ï¼Ÿ

<div class="practice-link">
  <a href="/projects/regression/sales-forecast.html" class="button">ä¸‹ä¸€ä¸ªé¡¹ç›®ï¼šé”€å”®é¢é¢„æµ‹</a>
</div> 