# å›å½’å®è·µæ¡ˆä¾‹

<div class="knowledge-card">
  <div class="knowledge-card__title">
    <span class="icon">ğŸ“š</span>æœ¬èŠ‚è¦ç‚¹
  </div>
  <div class="knowledge-card__content">
    <ul>
      <li>é€šè¿‡å®é™…æ¡ˆä¾‹å­¦ä¹ å›å½’åˆ†æçš„å®Œæ•´æµç¨‹</li>
      <li>æŒæ¡æ•°æ®é¢„å¤„ç†ã€ç‰¹å¾å·¥ç¨‹å’Œæ¨¡å‹é€‰æ‹©çš„å®è·µæŠ€å·§</li>
      <li>å­¦ä¹ å¦‚ä½•è§£é‡Šå›å½’æ¨¡å‹ç»“æœå¹¶æå‡ºä¸šåŠ¡å»ºè®®</li>
      <li>äº†è§£ä¸åŒé¢†åŸŸå›å½’åˆ†æçš„åº”ç”¨æ–¹æ³•</li>
    </ul>
  </div>
</div>

## æ¡ˆä¾‹ä¸€ï¼šæˆ¿ä»·é¢„æµ‹

æˆ¿ä»·é¢„æµ‹æ˜¯å›å½’åˆ†æçš„ç»å…¸åº”ç”¨åœºæ™¯ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®é›†è¿›è¡Œæ¼”ç¤ºã€‚

### é—®é¢˜æè¿°

é¢„æµ‹æ³¢å£«é¡¿åœ°åŒºçš„æˆ¿å±‹ä»·æ ¼ï¼Œå¸®åŠ©è´­æˆ¿è€…å’Œæˆ¿åœ°äº§å¼€å‘å•†åšå‡ºå†³ç­–ã€‚

### æ•°æ®æ¢ç´¢

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_boston

# åŠ è½½æ•°æ®
boston = load_boston()
X = boston.data
y = boston.target
feature_names = boston.feature_names

# åˆ›å»ºDataFrame
df = pd.DataFrame(X, columns=feature_names)
df['PRICE'] = y

# æŸ¥çœ‹æ•°æ®åŸºæœ¬ä¿¡æ¯
print(df.info())
print("\nç»Ÿè®¡æ‘˜è¦:")
print(df.describe())

# æŸ¥çœ‹ç›®æ ‡å˜é‡åˆ†å¸ƒ
plt.figure(figsize=(10, 6))
plt.hist(df['PRICE'], bins=30)
plt.xlabel('ä»·æ ¼ï¼ˆåƒç¾å…ƒï¼‰')
plt.ylabel('é¢‘æ•°')
plt.title('æ³¢å£«é¡¿æˆ¿ä»·åˆ†å¸ƒ')
plt.show()

# ç›¸å…³æ€§åˆ†æ
plt.figure(figsize=(12, 10))
correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ')
plt.show()

# æ•£ç‚¹å›¾çŸ©é˜µ
sns.pairplot(df[['PRICE', 'RM', 'LSTAT', 'DIS', 'NOX']])
plt.suptitle('ä¸»è¦ç‰¹å¾ä¸æˆ¿ä»·çš„å…³ç³»', y=1.02)
plt.show()
```

  </div>
</div>

### æ•°æ®é¢„å¤„ç†

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# åˆ›å»ºé¢„å¤„ç†ç®¡é“
preprocessor = Pipeline([
    ('scaler', StandardScaler())
])

# åº”ç”¨é¢„å¤„ç†
X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)
```

  </div>
</div>

### æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# åˆ›å»ºæ¨¡å‹
models = {
    'Linear Regression': LinearRegression(),
    'Ridge': Ridge(alpha=1.0),
    'Lasso': Lasso(alpha=0.1),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)
}

# è®­ç»ƒå’Œè¯„ä¼°
results = {}
for name, model in models.items():
    # è®­ç»ƒæ¨¡å‹
    model.fit(X_train_processed, y_train)
    
    # é¢„æµ‹
    y_pred = model.predict(X_test_processed)
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)
    
    # å­˜å‚¨ç»“æœ
    results[name] = {
        'MSE': mse,
        'RMSE': rmse,
        'RÂ²': r2
    }

# æ˜¾ç¤ºç»“æœ
for name, metrics in results.items():
    print(f"{name}:")
    print(f"  MSE: {metrics['MSE']:.4f}")
    print(f"  RMSE: {metrics['RMSE']:.4f}")
    print(f"  RÂ²: {metrics['RÂ²']:.4f}")

# å¯è§†åŒ–æ¯”è¾ƒ
plt.figure(figsize=(12, 6))
names = list(results.keys())
mse_values = [results[name]['MSE'] for name in names]
r2_values = [results[name]['RÂ²'] for name in names]

x = np.arange(len(names))
width = 0.35

fig, ax1 = plt.subplots(figsize=(12, 6))
ax2 = ax1.twinx()

rects1 = ax1.bar(x - width/2, mse_values, width, label='MSE', color='red', alpha=0.7)
rects2 = ax2.bar(x + width/2, r2_values, width, label='RÂ²', color='blue', alpha=0.7)

ax1.set_xlabel('æ¨¡å‹')
ax1.set_ylabel('MSE', color='red')
ax2.set_ylabel('RÂ²', color='blue')
ax1.set_xticks(x)
ax1.set_xticklabels(names, rotation=45, ha='right')
ax1.tick_params(axis='y', labelcolor='red')
ax2.tick_params(axis='y', labelcolor='blue')

fig.tight_layout()
plt.title('ä¸åŒæ¨¡å‹æ€§èƒ½æ¯”è¾ƒ')
plt.show()
```

  </div>
</div>

### ç‰¹å¾é‡è¦æ€§åˆ†æ

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
# ä½¿ç”¨éšæœºæ£®æ—çš„ç‰¹å¾é‡è¦æ€§
rf_model = models['Random Forest']
importances = rf_model.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(12, 6))
plt.title('ç‰¹å¾é‡è¦æ€§')
plt.bar(range(X.shape[1]), importances[indices], align='center')
plt.xticks(range(X.shape[1]), [feature_names[i] for i in indices], rotation=90)
plt.tight_layout()
plt.show()

# å‰5ä¸ªæœ€é‡è¦çš„ç‰¹å¾
print("æœ€é‡è¦çš„5ä¸ªç‰¹å¾:")
for i in range(5):
    print(f"{feature_names[indices[i]]}: {importances[indices[i]]:.4f}")
```

  </div>
</div>

### æ¨¡å‹ä¼˜åŒ–

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
from sklearn.model_selection import GridSearchCV

# é€‰æ‹©è¡¨ç°æœ€å¥½çš„æ¨¡å‹è¿›è¡Œä¼˜åŒ–ï¼ˆå‡è®¾æ˜¯æ¢¯åº¦æå‡ï¼‰
best_model = GradientBoostingRegressor(random_state=42)

# å®šä¹‰å‚æ•°ç½‘æ ¼
param_grid = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'max_depth': [3, 5, 7],
    'min_samples_split': [2, 5, 10],
    'subsample': [0.8, 0.9, 1.0]
}

# åˆ›å»ºç½‘æ ¼æœç´¢
grid_search = GridSearchCV(
    best_model,
    param_grid,
    cv=5,
    scoring='neg_mean_squared_error',
    n_jobs=-1
)

# è®­ç»ƒ
grid_search.fit(X_train_processed, y_train)

# æœ€ä½³å‚æ•°
print("æœ€ä½³å‚æ•°:")
print(grid_search.best_params_)

# ä½¿ç”¨æœ€ä½³æ¨¡å‹é¢„æµ‹
best_gbr = grid_search.best_estimator_
y_pred = best_gbr.predict(X_test_processed)

# è¯„ä¼°
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"ä¼˜åŒ–åçš„æ¨¡å‹æ€§èƒ½:")
print(f"  MSE: {mse:.4f}")
print(f"  RMSE: {rmse:.4f}")
print(f"  RÂ²: {r2:.4f}")
```

  </div>
</div>

### ç»“æœå¯è§†åŒ–

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
# é¢„æµ‹å€¼ä¸å®é™…å€¼æ¯”è¾ƒ
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel('å®é™…ä»·æ ¼')
plt.ylabel('é¢„æµ‹ä»·æ ¼')
plt.title('é¢„æµ‹å€¼ä¸å®é™…å€¼æ¯”è¾ƒ')
plt.grid(True)
plt.show()

# æ®‹å·®åˆ†æ
residuals = y_test - y_pred
plt.figure(figsize=(10, 6))
plt.scatter(y_pred, residuals, alpha=0.7)
plt.plot([y_pred.min(), y_pred.max()], [0, 0], 'k--', lw=2)
plt.xlabel('é¢„æµ‹ä»·æ ¼')
plt.ylabel('æ®‹å·®')
plt.title('æ®‹å·®åˆ†æ')
plt.grid(True)
plt.show()

# æ®‹å·®åˆ†å¸ƒ
plt.figure(figsize=(10, 6))
plt.hist(residuals, bins=30)
plt.xlabel('æ®‹å·®')
plt.ylabel('é¢‘æ•°')
plt.title('æ®‹å·®åˆ†å¸ƒ')
plt.grid(True)
plt.show()
```

  </div>
</div>

### ä¸šåŠ¡å»ºè®®

åŸºäºæ¨¡å‹ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥æå‡ºä»¥ä¸‹ä¸šåŠ¡å»ºè®®ï¼š

1. **å…³æ³¨é‡è¦ç‰¹å¾**ï¼šæ ¹æ®ç‰¹å¾é‡è¦æ€§ï¼Œæˆ¿å±‹çš„å¹³å‡æˆ¿é—´æ•°(RM)å’Œä½æ”¶å…¥äººå£æ¯”ä¾‹(LSTAT)å¯¹æˆ¿ä»·å½±å“æœ€å¤§ï¼Œå¼€å‘å•†åº”ä¼˜å…ˆè€ƒè™‘è¿™äº›å› ç´ 
2. **å®šä»·ç­–ç•¥**ï¼šä½¿ç”¨æ¨¡å‹é¢„æµ‹åˆç†çš„æˆ¿ä»·åŒºé—´ï¼Œé¿å…å®šä»·è¿‡é«˜æˆ–è¿‡ä½
3. **æŠ•èµ„å†³ç­–**ï¼šæ ¹æ®æ¨¡å‹é¢„æµ‹ï¼Œè¯†åˆ«æ½œåœ¨çš„ä½ä¼°æˆ–é«˜ä¼°æˆ¿äº§
4. **å¸‚åœºç»†åˆ†**ï¼šæ ¹æ®ä¸åŒç‰¹å¾ç»„åˆï¼Œå°†å¸‚åœºç»†åˆ†ä¸ºä¸åŒä»·æ ¼åŒºé—´çš„å­å¸‚åœº

<div class="knowledge-card">
  <div class="knowledge-card__title">
    <span class="icon">ğŸ’¡</span>ä½ çŸ¥é“å—ï¼Ÿ
  </div>
  <div class="knowledge-card__content">
    <p>æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®é›†æ˜¯ç”±å¡å†…åŸºæ¢…éš†å¤§å­¦çš„Harrisonå’ŒRubinfeldäº1978å¹´æ”¶é›†çš„ï¼ŒåŒ…å«äº†æ³¢å£«é¡¿éƒŠåŒº506ä¸ªäººå£æ™®æŸ¥åŒºçš„æˆ¿ä»·ä¸­ä½æ•°å’Œ13ä¸ªæ½œåœ¨å½±å“å› ç´ ã€‚å°½ç®¡è¿™ä¸ªæ•°æ®é›†å·²æœ‰å‡ åå¹´å†å²ï¼Œä½†å®ƒä»ç„¶æ˜¯å›å½’åˆ†ææ•™å­¦å’Œç ”ç©¶çš„ç»å…¸æ•°æ®é›†ã€‚</p>
  </div>
</div>

## æ¡ˆä¾‹äºŒï¼šé”€å”®é¢„æµ‹

é”€å”®é¢„æµ‹æ˜¯ä¼ä¸šå†³ç­–çš„é‡è¦ä¾æ®ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨é›¶å”®é”€å”®æ•°æ®è¿›è¡Œæ¼”ç¤ºã€‚

### é—®é¢˜æè¿°

é¢„æµ‹æœªæ¥å‡ ä¸ªæœˆçš„äº§å“é”€å”®é‡ï¼Œå¸®åŠ©ä¼ä¸šä¼˜åŒ–åº“å­˜ç®¡ç†å’Œè¥é”€ç­–ç•¥ã€‚

### æ•°æ®æ¢ç´¢

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.seasonal import seasonal_decompose

# åŠ è½½æ•°æ®ï¼ˆå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªåŒ…å«æ—¥æœŸå’Œé”€å”®é‡çš„CSVæ–‡ä»¶ï¼‰
# sales_data = pd.read_csv('sales_data.csv')
# ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ç”Ÿæˆä¸€äº›æ¨¡æ‹Ÿæ•°æ®
np.random.seed(42)
date_rng = pd.date_range(start='2018-01-01', end='2020-12-31', freq='D')
sales_data = pd.DataFrame(date_rng, columns=['date'])
sales_data['sales'] = np.random.randint(100, 200, size=(len(date_rng))) + \
                     20 * np.sin(np.arange(len(date_rng)) * 2 * np.pi / 365) + \
                     np.random.normal(0, 10, size=len(date_rng))
sales_data['weekday'] = sales_data['date'].dt.dayofweek
sales_data['month'] = sales_data['date'].dt.month
sales_data['year'] = sales_data['date'].dt.year
sales_data['day'] = sales_data['date'].dt.day

# æŸ¥çœ‹æ•°æ®
print(sales_data.head())
print("\nç»Ÿè®¡æ‘˜è¦:")
print(sales_data.describe())

# å¯è§†åŒ–é”€å”®è¶‹åŠ¿
plt.figure(figsize=(15, 7))
plt.plot(sales_data['date'], sales_data['sales'])
plt.title('é”€å”®è¶‹åŠ¿')
plt.xlabel('æ—¥æœŸ')
plt.ylabel('é”€å”®é‡')
plt.grid(True)
plt.show()

# æŒ‰æœˆä»½èšåˆ
monthly_sales = sales_data.groupby(['year', 'month'])['sales'].sum().reset_index()
monthly_sales['year_month'] = monthly_sales['year'].astype(str) + '-' + monthly_sales['month'].astype(str)

plt.figure(figsize=(15, 7))
plt.bar(monthly_sales['year_month'], monthly_sales['sales'])
plt.title('æœˆåº¦é”€å”®é‡')
plt.xlabel('å¹´-æœˆ')
plt.ylabel('é”€å”®é‡')
plt.xticks(rotation=90)
plt.grid(True, axis='y')
plt.show()

# å­£èŠ‚æ€§åˆ†è§£
# å°†æ•°æ®è½¬æ¢ä¸ºæ—¶é—´åºåˆ—æ ¼å¼
ts_data = sales_data.set_index('date')['sales']
decomposition = seasonal_decompose(ts_data, model='additive', period=365)

fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(15, 15))
decomposition.observed.plot(ax=ax1)
ax1.set_title('è§‚æµ‹å€¼')
decomposition.trend.plot(ax=ax2)
ax2.set_title('è¶‹åŠ¿')
decomposition.seasonal.plot(ax=ax3)
ax3.set_title('å­£èŠ‚æ€§')
decomposition.resid.plot(ax=ax4)
ax4.set_title('æ®‹å·®')
plt.tight_layout()
plt.show()

# æŒ‰æ˜ŸæœŸå‡ åˆ†æ
weekday_sales = sales_data.groupby('weekday')['sales'].mean().reset_index()
weekday_names = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']
weekday_sales['weekday_name'] = weekday_sales['weekday'].apply(lambda x: weekday_names[x])

plt.figure(figsize=(10, 6))
plt.bar(weekday_sales['weekday_name'], weekday_sales['sales'])
plt.title('ä¸åŒæ˜ŸæœŸå‡ çš„å¹³å‡é”€å”®é‡')
plt.xlabel('æ˜ŸæœŸå‡ ')
plt.ylabel('å¹³å‡é”€å”®é‡')
plt.grid(True, axis='y')
plt.show()
```

  </div>
</div>

### ç‰¹å¾å·¥ç¨‹

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
# åˆ›å»ºæ»åç‰¹å¾
for i in range(1, 8):
    sales_data[f'sales_lag_{i}'] = sales_data['sales'].shift(i)

# åˆ›å»ºæ»šåŠ¨å¹³å‡ç‰¹å¾
sales_data['sales_ma_7'] = sales_data['sales'].rolling(window=7).mean()
sales_data['sales_ma_30'] = sales_data['sales'].rolling(window=30).mean()

# åˆ›å»ºå­£èŠ‚æ€§ç‰¹å¾
sales_data['is_weekend'] = sales_data['weekday'].apply(lambda x: 1 if x >= 5 else 0)
sales_data['is_month_start'] = sales_data['day'].apply(lambda x: 1 if x <= 5 else 0)
sales_data['is_month_end'] = sales_data['day'].apply(lambda x: 1 if x >= 25 else 0)

# å»é™¤NaNå€¼
sales_data = sales_data.dropna()

# å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
features = ['weekday', 'month', 'is_weekend', 'is_month_start', 'is_month_end',
            'sales_lag_1', 'sales_lag_2', 'sales_lag_3', 'sales_lag_4', 
            'sales_lag_5', 'sales_lag_6', 'sales_lag_7',
            'sales_ma_7', 'sales_ma_30']

X = sales_data[features]
y = sales_data['sales']

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼‰
train_size = int(len(sales_data) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]
```

  </div>
</div>

### æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# åˆ›å»ºæ¨¡å‹
models = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)
}

# è®­ç»ƒå’Œè¯„ä¼°
results = {}
for name, model in models.items():
    # è®­ç»ƒæ¨¡å‹
    model.fit(X_train, y_train)
    
    # é¢„æµ‹
    y_pred = model.predict(X_test)
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    # å­˜å‚¨ç»“æœ
    results[name] = {
        'MSE': mse,
        'RMSE': rmse,
        'MAE': mae,
        'RÂ²': r2
    }

# æ˜¾ç¤ºç»“æœ
for name, metrics in results.items():
    print(f"{name}:")
    print(f"  MSE: {metrics['MSE']:.4f}")
    print(f"  RMSE: {metrics['RMSE']:.4f}")
    print(f"  MAE: {metrics['MAE']:.4f}")
    print(f"  RÂ²: {metrics['RÂ²']:.4f}")
```

  </div>
</div>

### é¢„æµ‹å¯è§†åŒ–

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
# ä½¿ç”¨è¡¨ç°æœ€å¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼ˆå‡è®¾æ˜¯æ¢¯åº¦æå‡ï¼‰
best_model = models['Gradient Boosting']
y_pred = best_model.predict(X_test)

# åˆ›å»ºåŒ…å«æ—¥æœŸã€å®é™…å€¼å’Œé¢„æµ‹å€¼çš„DataFrame
pred_df = pd.DataFrame({
    'date': sales_data['date'].iloc[train_size:].reset_index(drop=True),
    'actual': y_test.reset_index(drop=True),
    'predicted': y_pred
})

# å¯è§†åŒ–é¢„æµ‹ç»“æœ
plt.figure(figsize=(15, 7))
plt.plot(pred_df['date'], pred_df['actual'], label='å®é™…é”€å”®é‡')
plt.plot(pred_df['date'], pred_df['predicted'], label='é¢„æµ‹é”€å”®é‡', alpha=0.7)
plt.title('é”€å”®é‡é¢„æµ‹')
plt.xlabel('æ—¥æœŸ')
plt.ylabel('é”€å”®é‡')
plt.legend()
plt.grid(True)
plt.show()

# é¢„æµ‹è¯¯å·®åˆ†æ
pred_df['error'] = pred_df['actual'] - pred_df['predicted']
plt.figure(figsize=(15, 7))
plt.plot(pred_df['date'], pred_df['error'])
plt.axhline(y=0, color='r', linestyle='-')
plt.title('é¢„æµ‹è¯¯å·®')
plt.xlabel('æ—¥æœŸ')
plt.ylabel('è¯¯å·®')
plt.grid(True)
plt.show()

# è¯¯å·®åˆ†å¸ƒ
plt.figure(figsize=(10, 6))
plt.hist(pred_df['error'], bins=30)
plt.title('è¯¯å·®åˆ†å¸ƒ')
plt.xlabel('è¯¯å·®')
plt.ylabel('é¢‘æ•°')
plt.grid(True)
plt.show()
```

  </div>
</div>

### ç‰¹å¾é‡è¦æ€§åˆ†æ

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
# ä½¿ç”¨æ¢¯åº¦æå‡æ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§
importances = best_model.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(12, 6))
plt.title('ç‰¹å¾é‡è¦æ€§')
plt.bar(range(X.shape[1]), importances[indices], align='center')
plt.xticks(range(X.shape[1]), [features[i] for i in indices], rotation=90)
plt.tight_layout()
plt.show()

# å‰5ä¸ªæœ€é‡è¦çš„ç‰¹å¾
print("æœ€é‡è¦çš„5ä¸ªç‰¹å¾:")
for i in range(5):
    print(f"{features[indices[i]]}: {importances[indices[i]]:.4f}")
```

  </div>
</div>

### ä¸šåŠ¡å»ºè®®

åŸºäºé”€å”®é¢„æµ‹æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥æå‡ºä»¥ä¸‹ä¸šåŠ¡å»ºè®®ï¼š

1. **åº“å­˜ç®¡ç†**ï¼šæ ¹æ®é¢„æµ‹çš„é”€å”®é‡è°ƒæ•´åº“å­˜æ°´å¹³ï¼Œå‡å°‘åº“å­˜æˆæœ¬å’Œç¼ºè´§é£é™©
2. **ä¿ƒé”€æ´»åŠ¨**ï¼šåœ¨é¢„æµ‹é”€å”®ä½è°·æœŸç­–åˆ’ä¿ƒé”€æ´»åŠ¨ï¼Œæé«˜é”€å”®é‡
3. **äººåŠ›èµ„æºè§„åˆ’**ï¼šæ ¹æ®é¢„æµ‹çš„é”€å”®é«˜å³°æœŸåˆç†å®‰æ’äººå‘˜é…ç½®
4. **ä¾›åº”é“¾ä¼˜åŒ–**ï¼šæå‰é€šçŸ¥ä¾›åº”å•†é¢„æœŸçš„éœ€æ±‚å˜åŒ–ï¼Œä¼˜åŒ–ä¾›åº”é“¾
5. **å­£èŠ‚æ€§ç­–ç•¥**ï¼šé’ˆå¯¹å‘ç°çš„å­£èŠ‚æ€§æ¨¡å¼åˆ¶å®šç›¸åº”çš„è¥é”€å’Œäº§å“ç­–ç•¥

<div class="knowledge-card">
  <div class="knowledge-card__title">
    <span class="icon">âš ï¸</span>å¸¸è§è¯¯åŒº
  </div>
  <div class="knowledge-card__content">
    <ul>
      <li><strong>å¿½ç•¥å¤–éƒ¨å› ç´ </strong>ï¼šé”€å”®é¢„æµ‹åº”è€ƒè™‘å¸‚åœºè¶‹åŠ¿ã€ç«äº‰å¯¹æ‰‹æ´»åŠ¨ç­‰å¤–éƒ¨å› ç´ </li>
      <li><strong>è¿‡åº¦ä¾èµ–å†å²æ•°æ®</strong>ï¼šå¸‚åœºç¯å¢ƒå˜åŒ–å¯èƒ½å¯¼è‡´å†å²æ¨¡å¼ä¸å†é€‚ç”¨</li>
      <li><strong>å¿½ç•¥é¢„æµ‹åŒºé—´</strong>ï¼šæä¾›é¢„æµ‹åŒºé—´æ¯”å•ç‚¹é¢„æµ‹æ›´æœ‰ä»·å€¼</li>
      <li><strong>ç¼ºä¹æŒç»­æ›´æ–°</strong>ï¼šé”€å”®é¢„æµ‹æ¨¡å‹åº”å®šæœŸæ›´æ–°ä»¥é€‚åº”æ–°æ•°æ®</li>
    </ul>
  </div>
</div>

## å°ç»“ä¸æ€è€ƒ

é€šè¿‡å®é™…æ¡ˆä¾‹ï¼Œæˆ‘ä»¬å­¦ä¹ äº†å›å½’åˆ†æåœ¨æˆ¿ä»·é¢„æµ‹å’Œé”€å”®é¢„æµ‹ä¸­çš„åº”ç”¨ã€‚è¿™äº›æ¡ˆä¾‹å±•ç¤ºäº†ä»æ•°æ®æ¢ç´¢åˆ°æ¨¡å‹éƒ¨ç½²çš„å®Œæ•´æµç¨‹ã€‚

### å…³é”®è¦ç‚¹å›é¡¾

- æ•°æ®æ¢ç´¢å’Œå¯è§†åŒ–æ˜¯ç†è§£æ•°æ®ç‰¹æ€§çš„é‡è¦æ­¥éª¤
- ç‰¹å¾å·¥ç¨‹å¯¹æ¨¡å‹æ€§èƒ½æœ‰æ˜¾è‘—å½±å“
- ä¸åŒå›å½’æ¨¡å‹é€‚ç”¨äºä¸åŒç±»å‹çš„é—®é¢˜
- æ¨¡å‹è¯„ä¼°åº”ä½¿ç”¨å¤šç§æŒ‡æ ‡
- æ¨¡å‹ç»“æœçš„è§£é‡Šå’Œä¸šåŠ¡å»ºè®®æ˜¯æ•°æ®åˆ†æçš„æœ€ç»ˆç›®æ ‡

### æ€è€ƒé—®é¢˜

1. å¦‚ä½•å°†é¢†åŸŸçŸ¥è¯†èå…¥å›å½’æ¨¡å‹çš„æ„å»ºè¿‡ç¨‹ï¼Ÿ
2. åœ¨å®é™…ä¸šåŠ¡åœºæ™¯ä¸­ï¼Œå¦‚ä½•å¹³è¡¡æ¨¡å‹å¤æ‚åº¦å’Œå¯è§£é‡Šæ€§ï¼Ÿ
3. å¦‚ä½•å¤„ç†å›å½’åˆ†æä¸­çš„æ•°æ®è´¨é‡é—®é¢˜ï¼Ÿ

<BackToPath />

<div class="practice-link">
  <a href="/projects/regression.html" class="button">å‰å¾€å®è·µé¡¹ç›®</a>
</div> 