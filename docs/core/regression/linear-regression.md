# çº¿æ€§å›å½’

<div class="knowledge-card">
  <div class="knowledge-card__title">
    <span class="icon">ğŸ“š</span>æœ¬èŠ‚è¦ç‚¹
  </div>
  <div class="knowledge-card__content">
    <ul>
      <li>ç†è§£çº¿æ€§å›å½’çš„åŸºæœ¬åŸç†å’Œå‡è®¾</li>
      <li>æŒæ¡ç®€å•çº¿æ€§å›å½’å’Œå¤šå…ƒçº¿æ€§å›å½’çš„åŒºåˆ«</li>
      <li>å­¦ä¹ å¦‚ä½•è¯„ä¼°çº¿æ€§å›å½’æ¨¡å‹çš„æ€§èƒ½</li>
      <li>äº†è§£æ­£åˆ™åŒ–æŠ€æœ¯å¦‚ä½•æ”¹è¿›çº¿æ€§å›å½’</li>
    </ul>
  </div>
</div>

## çº¿æ€§å›å½’æ¦‚è¿°

çº¿æ€§å›å½’æ˜¯æœ€åŸºç¡€ã€åº”ç”¨æœ€å¹¿æ³›çš„å›å½’åˆ†ææ–¹æ³•ï¼Œç”¨äºå»ºç«‹å› å˜é‡ï¼ˆç›®æ ‡ï¼‰ä¸ä¸€ä¸ªæˆ–å¤šä¸ªè‡ªå˜é‡ï¼ˆç‰¹å¾ï¼‰ä¹‹é—´çš„å…³ç³»æ¨¡å‹ã€‚çº¿æ€§å›å½’å‡è®¾ç‰¹å¾å’Œç›®æ ‡ä¹‹é—´å­˜åœ¨çº¿æ€§å…³ç³»ã€‚

### ç®€å•çº¿æ€§å›å½’

ç®€å•çº¿æ€§å›å½’åªæ¶‰åŠä¸€ä¸ªè‡ªå˜é‡å’Œä¸€ä¸ªå› å˜é‡ï¼Œå…¶æ•°å­¦è¡¨è¾¾å¼ä¸ºï¼š

$$y = w_0 + w_1x + \varepsilon$$

å…¶ä¸­ï¼š
- $y$ æ˜¯å› å˜é‡ï¼ˆé¢„æµ‹ç›®æ ‡ï¼‰
- $x$ æ˜¯è‡ªå˜é‡ï¼ˆç‰¹å¾ï¼‰
- $w_0$ æ˜¯æˆªè·ï¼ˆåç½®é¡¹ï¼‰
- $w_1$ æ˜¯æ–œç‡ï¼ˆæƒé‡ï¼‰
- $\varepsilon$ æ˜¯è¯¯å·®é¡¹

ç®€å•çº¿æ€§å›å½’çš„ç›®æ ‡æ˜¯æ‰¾åˆ°æœ€ä½³çš„ $w_0$ å’Œ $w_1$ å€¼ï¼Œä½¿å¾—é¢„æµ‹å€¼ä¸å®é™…å€¼ä¹‹é—´çš„è¯¯å·®æœ€å°ã€‚

### å¤šå…ƒçº¿æ€§å›å½’

å¤šå…ƒçº¿æ€§å›å½’æ¶‰åŠå¤šä¸ªè‡ªå˜é‡ï¼Œå…¶æ•°å­¦è¡¨è¾¾å¼ä¸ºï¼š

$$y = w_0 + w_1x_1 + w_2x_2 + ... + w_nx_n + \varepsilon$$

æˆ–è€…ç”¨çŸ©é˜µå½¢å¼è¡¨ç¤ºï¼š

$$y = \mathbf{X}\mathbf{w} + \varepsilon$$

å…¶ä¸­ï¼š
- $y$ æ˜¯å› å˜é‡
- $x_1, x_2, ..., x_n$ æ˜¯è‡ªå˜é‡
- $w_0, w_1, w_2, ..., w_n$ æ˜¯æ¨¡å‹å‚æ•°
- $\varepsilon$ æ˜¯è¯¯å·®é¡¹
- $\mathbf{X}$ æ˜¯ç‰¹å¾çŸ©é˜µ
- $\mathbf{w}$ æ˜¯å‚æ•°å‘é‡

## çº¿æ€§å›å½’çš„å‡è®¾

çº¿æ€§å›å½’æ¨¡å‹åŸºäºä»¥ä¸‹å‡è®¾ï¼š

1. **çº¿æ€§å…³ç³»**ï¼šè‡ªå˜é‡å’Œå› å˜é‡ä¹‹é—´å­˜åœ¨çº¿æ€§å…³ç³»
2. **ç‹¬ç«‹æ€§**ï¼šè§‚æµ‹å€¼ä¹‹é—´ç›¸äº’ç‹¬ç«‹
3. **åŒæ–¹å·®æ€§**ï¼šè¯¯å·®é¡¹å…·æœ‰æ’å®šçš„æ–¹å·®
4. **æ­£æ€æ€§**ï¼šè¯¯å·®é¡¹æœä»æ­£æ€åˆ†å¸ƒ
5. **æ— å¤šé‡å…±çº¿æ€§**ï¼šè‡ªå˜é‡ä¹‹é—´ä¸å­˜åœ¨å®Œå…¨çº¿æ€§ç›¸å…³

å½“è¿™äº›å‡è®¾è¢«æ»¡è¶³æ—¶ï¼Œçº¿æ€§å›å½’æ¨¡å‹èƒ½å¤Ÿæä¾›æ— åä¸”æœ‰æ•ˆçš„å‚æ•°ä¼°è®¡ã€‚

## å‚æ•°ä¼°è®¡æ–¹æ³•

### æœ€å°äºŒä¹˜æ³•

æœ€å°äºŒä¹˜æ³•æ˜¯æœ€å¸¸ç”¨çš„å‚æ•°ä¼°è®¡æ–¹æ³•ï¼Œå…¶ç›®æ ‡æ˜¯æœ€å°åŒ–æ®‹å·®å¹³æ–¹å’Œï¼ˆRSSï¼‰ï¼š

$$RSS = (y - X\beta)^T(y - X\beta)$$

å¯¹äºç®€å•çº¿æ€§å›å½’ï¼Œæœ€å°äºŒä¹˜ä¼°è®¡çš„è§£æè§£ä¸ºï¼š

$$w_1 = \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n} (x_i - \bar{x})^2}$$

$$w_0 = \bar{y} - w_1\bar{x}$$

å¯¹äºå¤šå…ƒçº¿æ€§å›å½’ï¼Œå‚æ•°çš„çŸ©é˜µå½¢å¼è§£ä¸ºï¼š

$$\mathbf{w} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}$$

### æ¢¯åº¦ä¸‹é™æ³•

å½“æ•°æ®é‡å¾ˆå¤§æ—¶ï¼Œè®¡ç®— $(\mathbf{X}^T\mathbf{X})^{-1}$ å¯èƒ½è®¡ç®—é‡è¿‡å¤§ï¼Œæ­¤æ—¶å¯ä»¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•è¿­ä»£æ±‚è§£ï¼š

1. åˆå§‹åŒ–å‚æ•° $\mathbf{w}$
2. è®¡ç®—æŸå¤±å‡½æ•°å¯¹å‚æ•°çš„æ¢¯åº¦
3. æ²¿ç€æ¢¯åº¦çš„åæ–¹å‘æ›´æ–°å‚æ•°
4. é‡å¤æ­¥éª¤2å’Œ3ç›´åˆ°æ”¶æ•›

æ›´æ–°è§„åˆ™ä¸ºï¼š

$$w_j := w_j - \alpha \frac{\partial}{\partial w_j} RSS$$

å…¶ä¸­ $\alpha$ æ˜¯å­¦ä¹ ç‡ã€‚

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹ï¼šç®€å•çº¿æ€§å›å½’</div>
  <div class="code-example__content">

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# ç”Ÿæˆç¤ºä¾‹æ•°æ®
np.random.seed(0)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)

# ä½¿ç”¨sklearnçš„LinearRegression
model = LinearRegression()
model.fit(X, y)

# è·å–å‚æ•°
w0 = model.intercept_[0]
w1 = model.coef_[0][0]
print(f"æˆªè· (w0): {w0:.4f}")
print(f"æ–œç‡ (w1): {w1:.4f}")

# é¢„æµ‹
X_new = np.array([[0], [2]])
y_pred = model.predict(X_new)

# å¯è§†åŒ–
plt.figure(figsize=(10, 6))
plt.scatter(X, y, color='blue', label='æ•°æ®ç‚¹')
plt.plot(X_new, y_pred, 'r-', linewidth=2, label=f'y = {w0:.2f} + {w1:.2f}x')
plt.xlabel('X')
plt.ylabel('y')
plt.title('ç®€å•çº¿æ€§å›å½’')
plt.legend()
plt.grid(True)
plt.show()

# è¯„ä¼°æ¨¡å‹
y_pred_all = model.predict(X)
mse = mean_squared_error(y, y_pred_all)
r2 = r2_score(y, y_pred_all)
print(f"å‡æ–¹è¯¯å·® (MSE): {mse:.4f}")
print(f"å†³å®šç³»æ•° (RÂ²): {r2:.4f}")
```

  </div>
</div>

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹ï¼šå¤šå…ƒçº¿æ€§å›å½’</div>
  <div class="code-example__content">

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.datasets import fetch_california_housing

# åŠ è½½æ•°æ®é›†
housing = fetch_california_housing()
X = housing.data
y = housing.target

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# è®­ç»ƒæ¨¡å‹
model = LinearRegression()
model.fit(X_train, y_train)

# è·å–å‚æ•°
w0 = model.intercept_
w = model.coef_
print(f"æˆªè· (w0): {w0:.4f}")
print("ç‰¹å¾æƒé‡ (w):")
for i, feature_name in enumerate(housing.feature_names):
    print(f"  {feature_name}: {w[i]:.4f}")

# é¢„æµ‹
y_pred = model.predict(X_test)

# è¯„ä¼°æ¨¡å‹
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"å‡æ–¹è¯¯å·® (MSE): {mse:.4f}")
print(f"å†³å®šç³»æ•° (RÂ²): {r2:.4f}")

# å¯è§†åŒ–é¢„æµ‹ç»“æœ
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel('å®é™…å€¼')
plt.ylabel('é¢„æµ‹å€¼')
plt.title('å®é™…å€¼ vs é¢„æµ‹å€¼')
plt.grid(True)
plt.show()
```

  </div>
</div>

## æ­£åˆ™åŒ–æŠ€æœ¯

å½“ç‰¹å¾æ•°é‡è¾ƒå¤šæˆ–ç‰¹å¾ä¹‹é—´å­˜åœ¨å¤šé‡å…±çº¿æ€§æ—¶ï¼Œæ ‡å‡†çº¿æ€§å›å½’å¯èƒ½ä¼šå¯¼è‡´è¿‡æ‹Ÿåˆã€‚æ­£åˆ™åŒ–æŠ€æœ¯é€šè¿‡å‘æŸå¤±å‡½æ•°æ·»åŠ æƒ©ç½šé¡¹æ¥å‡å°‘è¿‡æ‹Ÿåˆé£é™©ã€‚

### Ridgeå›å½’ï¼ˆL2æ­£åˆ™åŒ–ï¼‰

Ridgeå›å½’é€šè¿‡æ·»åŠ ç³»æ•°å¹³æ–¹å’Œçš„æƒ©ç½šé¡¹æ¥å‡å°æ¨¡å‹å¤æ‚åº¦ï¼š

$$\min_{\mathbf{w}} \sum_{i=1}^{n} (y_i - \mathbf{w}^T \mathbf{x}_i)^2 + \alpha ||\mathbf{w}||_2^2$$

å…¶ä¸­ $\alpha$ æ˜¯æ­£åˆ™åŒ–å¼ºåº¦å‚æ•°ã€‚Ridgeå›å½’ä¼šå‡å°æ‰€æœ‰ç³»æ•°çš„å¤§å°ï¼Œä½†ä¸ä¼šä½¿ç³»æ•°å˜ä¸ºé›¶ã€‚

### Lassoå›å½’ï¼ˆL1æ­£åˆ™åŒ–ï¼‰

Lassoå›å½’ä½¿ç”¨ç³»æ•°ç»å¯¹å€¼å’Œä½œä¸ºæƒ©ç½šé¡¹ï¼š

$$\min_{\mathbf{w}} \sum_{i=1}^{n} (y_i - \mathbf{w}^T \mathbf{x}i)^2 + \alpha ||\mathbf{w}||_1$$

Lassoå›å½’çš„ä¸€ä¸ªé‡è¦ç‰¹æ€§æ˜¯å®ƒå¯ä»¥å°†ä¸€äº›ç³»æ•°ç²¾ç¡®åœ°ç¼©å‡ä¸ºé›¶ï¼Œä»è€Œå®ç°ç‰¹å¾é€‰æ‹©

### å¼¹æ€§ç½‘ç»œï¼ˆElastic Netï¼‰

å¼¹æ€§ç½‘ç»œç»“åˆäº†Ridgeå’ŒLassoçš„æƒ©ç½šé¡¹ï¼š

$$\min_{\mathbf{w}} \sum_{i=1}^{n} (y_i - \mathbf{w}^T \mathbf{x}_i)^2 + \alpha_1 ||\mathbf{w}||_1 + \alpha_2 ||\mathbf{w}||_2^2$$

å¼¹æ€§ç½‘ç»œå…‹æœäº†Lassoåœ¨å¤„ç†é«˜åº¦ç›¸å…³ç‰¹å¾æ—¶çš„ä¸€äº›é™åˆ¶ï¼ŒåŒæ—¶ä¿ç•™äº†ç‰¹å¾é€‰æ‹©çš„èƒ½åŠ›ã€‚

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹ï¼šæ­£åˆ™åŒ–çº¿æ€§å›å½’</div>
  <div class="code-example__content">

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from sklearn.datasets import fetch_california_housing

# åŠ è½½æ•°æ®
housing = fetch_california_housing()
X = housing.data
y = housing.target

# åˆ’åˆ†æ•°æ®é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# æ ‡å‡†åŒ–ç‰¹å¾
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# åˆ›å»ºæ¨¡å‹
ridge = Ridge(alpha=1.0)
lasso = Lasso(alpha=0.1)
elastic = ElasticNet(alpha=0.1, l1_ratio=0.5)

# è®­ç»ƒæ¨¡å‹
ridge.fit(X_train_scaled, y_train)
lasso.fit(X_train_scaled, y_train)
elastic.fit(X_train_scaled, y_train)

# é¢„æµ‹
y_pred_ridge = ridge.predict(X_test_scaled)
y_pred_lasso = lasso.predict(X_test_scaled)
y_pred_elastic = elastic.predict(X_test_scaled)

# è®¡ç®—MSE
mse_ridge = mean_squared_error(y_test, y_pred_ridge)
mse_lasso = mean_squared_error(y_test, y_pred_lasso)
mse_elastic = mean_squared_error(y_test, y_pred_elastic)

print(f"Ridge MSE: {mse_ridge:.4f}")
print(f"Lasso MSE: {mse_lasso:.4f}")
print(f"ElasticNet MSE: {mse_elastic:.4f}")

# å¯è§†åŒ–ç³»æ•°
plt.figure(figsize=(12, 6))
plt.plot(ridge.coef_, 's-', label='Ridge')
plt.plot(lasso.coef_, 'o-', label='Lasso')
plt.plot(elastic.coef_, '^-', label='ElasticNet')
plt.xlabel('ç‰¹å¾ç´¢å¼•')
plt.ylabel('ç³»æ•°å€¼')
plt.title('ä¸åŒæ­£åˆ™åŒ–æ–¹æ³•çš„ç³»æ•°æ¯”è¾ƒ')
plt.legend()
plt.grid(True)
plt.show()
```

  </div>
</div>

## çº¿æ€§å›å½’çš„ä¼˜ç¼ºç‚¹

### ä¼˜ç‚¹

- **ç®€å•æ˜“è§£é‡Š**ï¼šæ¨¡å‹ç®€å•ï¼Œå‚æ•°å…·æœ‰æ˜ç¡®çš„è§£é‡Š
- **è®¡ç®—æ•ˆç‡é«˜**ï¼šç‰¹åˆ«æ˜¯å¯¹äºå°åˆ°ä¸­ç­‰è§„æ¨¡çš„æ•°æ®é›†
- **æ— éœ€è°ƒæ•´è¶…å‚æ•°**ï¼šæ ‡å‡†çº¿æ€§å›å½’æ²¡æœ‰éœ€è¦è°ƒæ•´çš„è¶…å‚æ•°
- **å¯ä½œä¸ºåŸºçº¿æ¨¡å‹**ï¼šä¸ºæ›´å¤æ‚çš„æ¨¡å‹æä¾›æ¯”è¾ƒåŸºå‡†

### ç¼ºç‚¹

- **å‡è®¾é™åˆ¶**ï¼šå‡è®¾ç‰¹å¾å’Œç›®æ ‡ä¹‹é—´å­˜åœ¨çº¿æ€§å…³ç³»
- **å¯¹å¼‚å¸¸å€¼æ•æ„Ÿ**ï¼šå¼‚å¸¸å€¼å¯èƒ½å¯¹æ¨¡å‹å‚æ•°äº§ç”Ÿæ˜¾è‘—å½±å“
- **æ— æ³•æ•æ‰éçº¿æ€§å…³ç³»**ï¼šå½“æ•°æ®å…³ç³»å¤æ‚æ—¶è¡¨ç°ä¸ä½³
- **å¤šé‡å…±çº¿æ€§é—®é¢˜**ï¼šå½“ç‰¹å¾é«˜åº¦ç›¸å…³æ—¶ï¼Œå‚æ•°ä¼°è®¡ä¸ç¨³å®š

## å®é™…åº”ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹ï¼šé¢„æµ‹æˆ¿ä»·

æˆ¿ä»·é¢„æµ‹æ˜¯çº¿æ€§å›å½’çš„ç»å…¸åº”ç”¨åœºæ™¯ã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨åŠ å·æˆ¿ä»·æ•°æ®é›†çš„ç¤ºä¾‹ï¼š

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹ï¼šåŠ å·æˆ¿ä»·é¢„æµ‹</div>
  <div class="code-example__content">

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score

# åŠ è½½æ•°æ®
housing = fetch_california_housing()
X = pd.DataFrame(housing.data, columns=housing.feature_names)
y = housing.target

# æ•°æ®æ¢ç´¢
print("æ•°æ®é›†å½¢çŠ¶:", X.shape)
print("ç‰¹å¾åç§°:", housing.feature_names)
print("ç‰¹å¾æè¿°:")
print(X.describe())

# ç›¸å…³æ€§åˆ†æ
data = pd.DataFrame(housing.data, columns=housing.feature_names)
data['PRICE'] = housing.target
correlation = data.corr()
plt.figure(figsize=(12, 10))
plt.imshow(correlation, cmap='coolwarm', interpolation='none', aspect='auto')
plt.colorbar()
plt.xticks(range(len(correlation)), correlation.columns, rotation=90)
plt.yticks(range(len(correlation)), correlation.columns)
plt.title('ç‰¹å¾ç›¸å…³æ€§çƒ­å›¾')
plt.show()

# åˆ’åˆ†æ•°æ®é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# æ ‡å‡†åŒ–ç‰¹å¾
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# è®­ç»ƒæ¨¡å‹
model = LinearRegression()
model.fit(X_train_scaled, y_train)

# è·å–ç³»æ•°
coefficients = pd.DataFrame({
    'Feature': housing.feature_names,
    'Coefficient': model.coef_
})
coefficients = coefficients.sort_values('Coefficient', ascending=False)

# å¯è§†åŒ–ç³»æ•°
plt.figure(figsize=(10, 6))
plt.barh(coefficients['Feature'], coefficients['Coefficient'])
plt.xlabel('ç³»æ•°å€¼')
plt.title('ç‰¹å¾ç³»æ•°')
plt.grid(True)
plt.show()

# é¢„æµ‹å’Œè¯„ä¼°
y_train_pred = model.predict(X_train_scaled)
y_test_pred = model.predict(X_test_scaled)

train_mse = mean_squared_error(y_train, y_train_pred)
test_mse = mean_squared_error(y_test, y_test_pred)
train_r2 = r2_score(y_train, y_train_pred)
test_r2 = r2_score(y_test, y_test_pred)

print(f"è®­ç»ƒé›† MSE: {train_mse:.4f}")
print(f"æµ‹è¯•é›† MSE: {test_mse:.4f}")
print(f"è®­ç»ƒé›† RÂ²: {train_r2:.4f}")
print(f"æµ‹è¯•é›† RÂ²: {test_r2:.4f}")

# å¯è§†åŒ–é¢„æµ‹ç»“æœ
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_test_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel('å®é™…æˆ¿ä»·')
plt.ylabel('é¢„æµ‹æˆ¿ä»·')
plt.title('å®é™…æˆ¿ä»· vs é¢„æµ‹æˆ¿ä»·')
plt.grid(True)
plt.show()

# æ®‹å·®åˆ†æ
residuals = y_test - y_test_pred
plt.figure(figsize=(10, 6))
plt.scatter(y_test_pred, residuals, alpha=0.5)
plt.hlines(y=0, xmin=y_test_pred.min(), xmax=y_test_pred.max(), colors='r', linestyles='--')
plt.xlabel('é¢„æµ‹å€¼')
plt.ylabel('æ®‹å·®')
plt.title('æ®‹å·®å›¾')
plt.grid(True)
plt.show()
```

  </div>
</div>

## æ€»ç»“

çº¿æ€§å›å½’æ˜¯æ•°æ®æŒ–æ˜å’Œæœºå™¨å­¦ä¹ ä¸­æœ€åŸºç¡€çš„ç®—æ³•ä¹‹ä¸€ï¼Œå°½ç®¡ç®€å•ï¼Œä½†åœ¨è®¸å¤šå®é™…åº”ç”¨ä¸­è¡¨ç°è‰¯å¥½ã€‚ç†è§£çº¿æ€§å›å½’çš„åŸç†å’Œå‡è®¾ï¼ŒæŒæ¡å‚æ•°ä¼°è®¡æ–¹æ³•å’Œæ­£åˆ™åŒ–æŠ€æœ¯ï¼Œå¯¹äºæ„å»ºæœ‰æ•ˆçš„é¢„æµ‹æ¨¡å‹è‡³å…³é‡è¦ã€‚

<div class="practice-link">
  <a href="/projects/prediction.html" class="button">å‰å¾€å®è·µé¡¹ç›®</a>
</div> 