# æœ´ç´ è´å¶æ–¯ç®—æ³•

<div class="knowledge-card">
  <div class="knowledge-card__title">
    <span class="icon">ğŸ“š</span>æœ¬èŠ‚è¦ç‚¹
  </div>
  <div class="knowledge-card__content">
    <ul>
      <li>ç†è§£è´å¶æ–¯å®šç†åŠå…¶åœ¨åˆ†ç±»ä¸­çš„åº”ç”¨</li>
      <li>æŒæ¡æœ´ç´ è´å¶æ–¯ç®—æ³•çš„åŸºæœ¬åŸç†</li>
      <li>å­¦ä¹ ä¸åŒç±»å‹çš„æœ´ç´ è´å¶æ–¯æ¨¡å‹</li>
      <li>å®è·µæœ´ç´ è´å¶æ–¯åœ¨æ–‡æœ¬åˆ†ç±»ä¸­çš„åº”ç”¨</li>
    </ul>
  </div>
</div>

## è´å¶æ–¯å®šç†åŸºç¡€

æœ´ç´ è´å¶æ–¯ç®—æ³•åŸºäºè´å¶æ–¯å®šç†ï¼Œè¿™æ˜¯ä¸€ä¸ªæè¿°äº‹ä»¶æ¡ä»¶æ¦‚ç‡çš„æ•°å­¦å…¬å¼ã€‚

### è´å¶æ–¯å®šç†

è´å¶æ–¯å®šç†è¡¨ç¤ºä¸ºï¼š

$$P(A|B) = \frac{P(B|A) \times P(A)}{P(B)}$$

å…¶ä¸­ï¼š
- $P(A|B)$ æ˜¯å·²çŸ¥Bå‘ç”ŸåAå‘ç”Ÿçš„æ¡ä»¶æ¦‚ç‡ï¼ˆåéªŒæ¦‚ç‡ï¼‰
- $P(B|A)$ æ˜¯å·²çŸ¥Aå‘ç”ŸåBå‘ç”Ÿçš„æ¡ä»¶æ¦‚ç‡ï¼ˆä¼¼ç„¶æ¦‚ç‡ï¼‰
- $P(A)$ æ˜¯Aå‘ç”Ÿçš„æ¦‚ç‡ï¼ˆå…ˆéªŒæ¦‚ç‡ï¼‰
- $P(B)$ æ˜¯Bå‘ç”Ÿçš„æ¦‚ç‡ï¼ˆè¾¹ç¼˜æ¦‚ç‡ï¼‰

### åœ¨åˆ†ç±»é—®é¢˜ä¸­çš„åº”ç”¨

åœ¨åˆ†ç±»é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›è®¡ç®—ç»™å®šç‰¹å¾$X$æ—¶ï¼Œæ ·æœ¬å±äºç±»åˆ«$y$çš„æ¦‚ç‡$P(y|X)$ï¼š

$$P(y|X) = \frac{P(X|y) \times P(y)}{P(X)}$$

å…¶ä¸­ï¼š
- $P(y|X)$ æ˜¯ç»™å®šç‰¹å¾Xæ—¶ç±»åˆ«ä¸ºyçš„æ¦‚ç‡ï¼ˆæˆ‘ä»¬è¦æ±‚çš„ç›®æ ‡ï¼‰
- $P(X|y)$ æ˜¯ç±»åˆ«ä¸ºyæ—¶è§‚å¯Ÿåˆ°ç‰¹å¾Xçš„æ¦‚ç‡
- $P(y)$ æ˜¯ç±»åˆ«yçš„å…ˆéªŒæ¦‚ç‡
- $P(X)$ æ˜¯ç‰¹å¾Xå‡ºç°çš„æ¦‚ç‡ï¼ˆå¯¹æ‰€æœ‰ç±»åˆ«æ¥è¯´æ˜¯å¸¸æ•°ï¼‰

<div class="knowledge-card">
  <div class="knowledge-card__title">
    <span class="icon">ğŸ’¡</span>ä½ çŸ¥é“å—ï¼Ÿ
  </div>
  <div class="knowledge-card__content">
    <p>è´å¶æ–¯å®šç†ä»¥è‹±å›½æ•°å­¦å®¶æ‰˜é©¬æ–¯Â·è´å¶æ–¯(Thomas Bayes, 1702-1761)å‘½åã€‚æœ‰è¶£çš„æ˜¯ï¼Œè´å¶æ–¯æœ¬äººå¹¶æœªå‘è¡¨è¿™ä¸ªå®šç†ï¼Œå®ƒæ˜¯åœ¨ä»–å»ä¸–åç”±ç†æŸ¥å¾·Â·æ™®è±æ–¯(Richard Price)æ•´ç†å¹¶å‘è¡¨çš„ã€‚è´å¶æ–¯å®šç†ä¸ä»…æ˜¯æœºå™¨å­¦ä¹ çš„åŸºç¡€ï¼Œä¹Ÿåœ¨ç»Ÿè®¡å­¦ã€åŒ»å­¦è¯Šæ–­ã€æ³•å¾‹æ¨ç†ç­‰å¤šä¸ªé¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ã€‚</p>
  </div>
</div>

## æœ´ç´ è´å¶æ–¯ç®—æ³•åŸç†

### "æœ´ç´ "å‡è®¾

æœ´ç´ è´å¶æ–¯ä¹‹æ‰€ä»¥"æœ´ç´ "ï¼Œæ˜¯å› ä¸ºå®ƒåšäº†ä¸€ä¸ªç®€åŒ–å‡è®¾ï¼š**æ‰€æœ‰ç‰¹å¾ä¹‹é—´ç›¸äº’ç‹¬ç«‹**ã€‚è¿™æ„å‘³ç€ï¼š

$$P(X|y) = P(x_1|y) \times P(x_2|y) \times ... \times P(x_n|y)$$

å…¶ä¸­$x_1, x_2, ..., x_n$æ˜¯ç‰¹å¾å‘é‡$X$çš„å„ä¸ªç‰¹å¾ã€‚

è¿™ä¸ªå‡è®¾è™½ç„¶åœ¨å®é™…ä¸­å¾ˆå°‘å®Œå…¨æˆç«‹ï¼Œä½†æœ´ç´ è´å¶æ–¯åœ¨è®¸å¤šå®é™…é—®é¢˜ä¸­ä»ç„¶è¡¨ç°è‰¯å¥½ã€‚

### åˆ†ç±»å†³ç­–

æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨é€‰æ‹©å…·æœ‰æœ€å¤§åéªŒæ¦‚ç‡çš„ç±»åˆ«ï¼š

$$\hat{y} = \arg\max_y P(y|X) = \arg\max_y \frac{P(X|y)P(y)}{P(X)}$$

ç”±äº$P(X)$å¯¹æ‰€æœ‰ç±»åˆ«éƒ½ç›¸åŒï¼Œå¯ä»¥ç®€åŒ–ä¸ºï¼š

$$\hat{y} = \arg\max_y P(X|y)P(y) = \arg\max_y P(y) \prod_{i=1}^{n} P(x_i|y)$$

<div class="visualization-container">
  <div class="visualization-title">æœ´ç´ è´å¶æ–¯åˆ†ç±»è¿‡ç¨‹</div>
  <div class="visualization-content">
    <img src="/images/naive_bayes_process.svg" alt="æœ´ç´ è´å¶æ–¯åˆ†ç±»è¿‡ç¨‹">
  </div>
  <div class="visualization-caption">
    å›¾: æœ´ç´ è´å¶æ–¯åˆ†ç±»è¿‡ç¨‹ã€‚ä»è®­ç»ƒæ•°æ®ä¸­å­¦ä¹ å…ˆéªŒæ¦‚ç‡å’Œæ¡ä»¶æ¦‚ç‡ï¼Œç„¶åç”¨è¿™äº›æ¦‚ç‡è®¡ç®—æ–°æ ·æœ¬çš„åéªŒæ¦‚ç‡ï¼Œé€‰æ‹©åéªŒæ¦‚ç‡æœ€å¤§çš„ç±»åˆ«ä½œä¸ºé¢„æµ‹ç»“æœã€‚
  </div>
</div>

## æœ´ç´ è´å¶æ–¯çš„å˜ä½“

æ ¹æ®ç‰¹å¾çš„åˆ†å¸ƒå‡è®¾ï¼Œæœ´ç´ è´å¶æ–¯æœ‰å‡ ç§ä¸»è¦å˜ä½“ï¼š

### 1. é«˜æ–¯æœ´ç´ è´å¶æ–¯

å‡è®¾ç‰¹å¾æœä»é«˜æ–¯åˆ†å¸ƒï¼Œé€‚ç”¨äºè¿ç»­å‹ç‰¹å¾ï¼š

$$P(x_i|y) = \frac{1}{\sqrt{2\pi\sigma_y^2}} \exp\left(-\frac{(x_i - \mu_y)^2}{2\sigma_y^2}\right)$$

å…¶ä¸­$\mu_y$å’Œ$\sigma_y^2$åˆ†åˆ«æ˜¯ç±»åˆ«$y$ä¸‹ç‰¹å¾$x_i$çš„å‡å€¼å’Œæ–¹å·®ã€‚

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
from sklearn.naive_bayes import GaussianNB
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# åŠ è½½æ•°æ®
iris = load_iris()
X, y = iris.data, iris.target

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# åˆ›å»ºå¹¶è®­ç»ƒé«˜æ–¯æœ´ç´ è´å¶æ–¯æ¨¡å‹
gnb = GaussianNB()
gnb.fit(X_train, y_train)

# é¢„æµ‹
y_pred = gnb.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"å‡†ç¡®ç‡: {accuracy:.4f}")
```

  </div>
</div>

### 2. å¤šé¡¹å¼æœ´ç´ è´å¶æ–¯

å‡è®¾ç‰¹å¾æ˜¯ç¦»æ•£çš„ï¼Œæœä»å¤šé¡¹å¼åˆ†å¸ƒï¼Œé€‚ç”¨äºæ–‡æœ¬åˆ†ç±»ç­‰è®¡æ•°æ•°æ®ï¼š

$$P(x_i|y) = \frac{n_{yi} + \alpha}{n_y + \alpha n}$$

å…¶ä¸­ï¼š
- $n_{yi}$ æ˜¯ç±»åˆ«$y$ä¸­ç‰¹å¾$i$çš„å‡ºç°æ¬¡æ•°
- $n_y$ æ˜¯ç±»åˆ«$y$ä¸­æ‰€æœ‰ç‰¹å¾çš„å‡ºç°æ¬¡æ•°æ€»å’Œ
- $\alpha$ æ˜¯å¹³æ»‘å‚æ•°ï¼ˆæ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼‰
- $n$ æ˜¯ç‰¹å¾çš„æ€»æ•°

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# ç¤ºä¾‹æ–‡æœ¬æ•°æ®
texts = [
    'I love this movie', 'This movie is great', 'The acting was amazing',
    'I hated this film', 'Terrible movie', 'The worst film I have seen',
    'The plot was interesting', 'I enjoyed the story', 'Great characters'
]
labels = [1, 1, 1, 0, 0, 0, 1, 1, 1]  # 1=æ­£é¢è¯„ä»·, 0=è´Ÿé¢è¯„ä»·

# æ–‡æœ¬è½¬æ¢ä¸ºç‰¹å¾å‘é‡
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(texts)

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)

# åˆ›å»ºå¹¶è®­ç»ƒå¤šé¡¹å¼æœ´ç´ è´å¶æ–¯æ¨¡å‹
mnb = MultinomialNB(alpha=1.0)  # alphaæ˜¯æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘å‚æ•°
mnb.fit(X_train, y_train)

# é¢„æµ‹
y_pred = mnb.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"å‡†ç¡®ç‡: {accuracy:.4f}")

# æŸ¥çœ‹ç‰¹å¾é‡è¦æ€§
feature_names = vectorizer.get_feature_names_out()
for class_idx in range(len(mnb.classes_)):
    top_features = sorted(zip(mnb.feature_log_prob_[class_idx], feature_names), reverse=True)[:5]
    print(f"ç±»åˆ« {mnb.classes_[class_idx]} çš„å‰5ä¸ªé‡è¦è¯: {[word for _, word in top_features]}")
```

  </div>
</div>

### 3. ä¼¯åŠªåˆ©æœ´ç´ è´å¶æ–¯

å‡è®¾ç‰¹å¾æ˜¯äºŒå…ƒçš„ï¼ˆ0æˆ–1ï¼‰ï¼Œæœä»ä¼¯åŠªåˆ©åˆ†å¸ƒï¼Œé€‚ç”¨äºæ–‡æ¡£åˆ†ç±»ç­‰äºŒå…ƒç‰¹å¾ï¼š

$$P(x_i|y) = P(i|y)^{x_i} \times (1-P(i|y))^{(1-x_i)}$$

å…¶ä¸­$P(i|y)$æ˜¯ç±»åˆ«$y$ä¸­ç‰¹å¾$i$å‡ºç°çš„æ¦‚ç‡ã€‚

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
from sklearn.naive_bayes import BernoulliNB
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# ä½¿ç”¨ä¸å¤šé¡¹å¼æœ´ç´ è´å¶æ–¯ç›¸åŒçš„ç¤ºä¾‹æ•°æ®
# ä½†ä½¿ç”¨äºŒå…ƒç‰¹å¾ï¼ˆè¯æ˜¯å¦å‡ºç°ï¼Œè€Œéå‡ºç°æ¬¡æ•°ï¼‰
vectorizer = CountVectorizer(binary=True)
X = vectorizer.fit_transform(texts)

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)

# åˆ›å»ºå¹¶è®­ç»ƒä¼¯åŠªåˆ©æœ´ç´ è´å¶æ–¯æ¨¡å‹
bnb = BernoulliNB(alpha=1.0)
bnb.fit(X_train, y_train)

# é¢„æµ‹
y_pred = bnb.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"å‡†ç¡®ç‡: {accuracy:.4f}")
```

  </div>
</div>

## æœ´ç´ è´å¶æ–¯åœ¨æ–‡æœ¬åˆ†ç±»ä¸­çš„åº”ç”¨

æœ´ç´ è´å¶æ–¯æ˜¯æ–‡æœ¬åˆ†ç±»ï¼ˆå¦‚åƒåœ¾é‚®ä»¶è¿‡æ»¤ï¼‰çš„ç»å…¸ç®—æ³•ï¼Œä¸‹é¢æ˜¯ä¸€ä¸ªå®Œæ•´çš„åƒåœ¾é‚®ä»¶åˆ†ç±»ç¤ºä¾‹ï¼š

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix

# åŠ è½½æ•°æ®ï¼ˆç¤ºä¾‹ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ›¿æ¢ä¸ºçœŸå®æ•°æ®ï¼‰
# å‡è®¾æ•°æ®æ ¼å¼ä¸ºï¼šé‚®ä»¶å†…å®¹å’Œæ ‡ç­¾ï¼ˆ1=åƒåœ¾é‚®ä»¶ï¼Œ0=æ­£å¸¸é‚®ä»¶ï¼‰
emails = [
    "Get rich quick! Guaranteed money in just one week.",
    "Meeting scheduled for tomorrow at 10 AM.",
    "Congratulations! You've won a free iPhone. Click here to claim.",
    "Please review the quarterly report before Friday.",
    "URGENT: Your account has been compromised. Verify now!",
    "Reminder: Team lunch at noon today.",
    "Free vacation! Limited time offer. Act now!",
    "The project deadline has been extended to next Monday."
]
labels = [1, 0, 1, 0, 1, 0, 1, 0]

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(
    emails, labels, test_size=0.3, random_state=42
)

# åˆ›å»ºå¤„ç†æµæ°´çº¿
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(stop_words='english', max_features=1000)),
    ('classifier', MultinomialNB(alpha=0.1))
])

# è®­ç»ƒæ¨¡å‹
pipeline.fit(X_train, y_train)

# é¢„æµ‹
y_pred = pipeline.predict(X_test)

# è¯„ä¼°
print(classification_report(y_test, y_pred, target_names=['æ­£å¸¸é‚®ä»¶', 'åƒåœ¾é‚®ä»¶']))
print("\næ··æ·†çŸ©é˜µ:")
print(confusion_matrix(y_test, y_pred))

# æŸ¥çœ‹é‡è¦ç‰¹å¾
tfidf = pipeline.named_steps['tfidf']
nb = pipeline.named_steps['classifier']
feature_names = tfidf.get_feature_names_out()

# è·å–åƒåœ¾é‚®ä»¶ç±»åˆ«çš„é«˜æ¦‚ç‡è¯
spam_idx = np.where(nb.classes_ == 1)[0][0]
top_spam_features = sorted(zip(nb.feature_log_prob_[spam_idx], feature_names), reverse=True)[:10]
print("\nåƒåœ¾é‚®ä»¶ä¸­çš„é«˜æ¦‚ç‡è¯:")
for prob, word in top_spam_features:
    print(f"{word}: {np.exp(prob):.4f}")

# æµ‹è¯•æ–°é‚®ä»¶
new_emails = [
    "Congratulations! You've been selected for a free cruise.",
    "Please submit your timesheet by end of day."
]
predictions = pipeline.predict(new_emails)
for email, pred in zip(new_emails, predictions):
    print(f"\né‚®ä»¶: {email}")
    print(f"é¢„æµ‹: {'åƒåœ¾é‚®ä»¶' if pred == 1 else 'æ­£å¸¸é‚®ä»¶'}")
```

  </div>
</div>

## æœ´ç´ è´å¶æ–¯çš„ä¼˜ç¼ºç‚¹

### ä¼˜ç‚¹

1. **è®¡ç®—æ•ˆç‡é«˜**ï¼šè®­ç»ƒå’Œé¢„æµ‹é€Ÿåº¦å¿«ï¼Œé€‚åˆå¤§è§„æ¨¡æ•°æ®é›†
2. **å¯¹å°æ•°æ®é›†æ•ˆæœå¥½**ï¼šå³ä½¿è®­ç»ƒæ ·æœ¬è¾ƒå°‘ä¹Ÿèƒ½è·å¾—ä¸é”™çš„æ€§èƒ½
3. **å¤„ç†é«˜ç»´æ•°æ®èƒ½åŠ›å¼º**ï¼šç‰¹åˆ«é€‚åˆæ–‡æœ¬åˆ†ç±»ç­‰é«˜ç»´ç¨€ç–æ•°æ®
4. **æ˜“äºå®ç°å’Œç†è§£**ï¼šç®—æ³•ç®€å•ç›´è§‚ï¼Œå®¹æ˜“è§£é‡Š

### ç¼ºç‚¹

1. **ç‰¹å¾ç‹¬ç«‹æ€§å‡è®¾**ï¼šç°å®ä¸­ç‰¹å¾å¾€å¾€ä¸æ˜¯å®Œå…¨ç‹¬ç«‹çš„
2. **é›¶æ¦‚ç‡é—®é¢˜**ï¼šéœ€è¦ä½¿ç”¨å¹³æ»‘æŠ€æœ¯å¤„ç†è®­ç»ƒé›†ä¸­æœªå‡ºç°çš„ç‰¹å¾
3. **å¯¹ç‰¹å¾æƒé‡ä¸æ•æ„Ÿ**ï¼šæ— æ³•ç›´æ¥å¤„ç†ä¸€ä¸ªç‰¹å¾æ¯”å¦ä¸€ä¸ªæ›´é‡è¦çš„æƒ…å†µ
4. **å¯¹æ•°å€¼ç‰¹å¾çš„å»ºæ¨¡ä¸å¤Ÿç²¾ç¡®**ï¼šé«˜æ–¯å‡è®¾å¯èƒ½ä¸ç¬¦åˆå®é™…åˆ†å¸ƒ

<div class="knowledge-card">
  <div class="knowledge-card__title">
    <span class="icon">âš ï¸</span>å¸¸è§è¯¯åŒº
  </div>
  <div class="knowledge-card__content">
    <ul>
      <li><strong>å¿½ç•¥ç‰¹å¾ç‹¬ç«‹æ€§å‡è®¾</strong>ï¼šåœ¨ç‰¹å¾é«˜åº¦ç›¸å…³çš„æƒ…å†µä¸‹æœªè¿›è¡Œç‰¹å¾é€‰æ‹©æˆ–é™ç»´</li>
      <li><strong>å¿½ç•¥å¹³æ»‘å¤„ç†</strong>ï¼šæœªè®¾ç½®é€‚å½“çš„alphaå€¼å¤„ç†é›¶æ¦‚ç‡é—®é¢˜</li>
      <li><strong>é”™è¯¯é€‰æ‹©å˜ä½“</strong>ï¼šå¯¹è¿ç»­æ•°æ®ä½¿ç”¨å¤šé¡¹å¼æœ´ç´ è´å¶æ–¯æˆ–å¯¹æ–‡æœ¬æ•°æ®ä½¿ç”¨é«˜æ–¯æœ´ç´ è´å¶æ–¯</li>
      <li><strong>è¿‡åº¦ä¾èµ–æ¦‚ç‡è¾“å‡º</strong>ï¼šæœ´ç´ è´å¶æ–¯çš„æ¦‚ç‡ä¼°è®¡é€šå¸¸ä¸å¤Ÿå‡†ç¡®ï¼Œä¸åº”è¿‡åº¦ä¾èµ–å…¶æ¦‚ç‡å€¼</li>
    </ul>
  </div>
</div>

## å°ç»“ä¸æ€è€ƒ

æœ´ç´ è´å¶æ–¯æ˜¯ä¸€ç§ç®€å•è€Œå¼ºå¤§çš„åˆ†ç±»ç®—æ³•ï¼Œç‰¹åˆ«é€‚åˆæ–‡æœ¬åˆ†ç±»ç­‰é«˜ç»´æ•°æ®é—®é¢˜ã€‚å°½ç®¡å…¶å‡è®¾åœ¨å®é™…ä¸­å¾ˆå°‘å®Œå…¨æˆç«‹ï¼Œä½†ç”±äºå…¶ç®€å•æ€§å’Œè®¡ç®—æ•ˆç‡ï¼Œä»ç„¶æ˜¯è®¸å¤šåº”ç”¨çš„é¦–é€‰ç®—æ³•ã€‚

### å…³é”®è¦ç‚¹å›é¡¾

- æœ´ç´ è´å¶æ–¯åŸºäºè´å¶æ–¯å®šç†å’Œç‰¹å¾ç‹¬ç«‹æ€§å‡è®¾
- ä¸»è¦å˜ä½“åŒ…æ‹¬é«˜æ–¯ã€å¤šé¡¹å¼å’Œä¼¯åŠªåˆ©æœ´ç´ è´å¶æ–¯
- åœ¨æ–‡æœ¬åˆ†ç±»ç­‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²
- éœ€è¦ä½¿ç”¨å¹³æ»‘æŠ€æœ¯å¤„ç†é›¶æ¦‚ç‡é—®é¢˜

### æ€è€ƒé—®é¢˜

1. ä¸ºä»€ä¹ˆæœ´ç´ è´å¶æ–¯åœ¨ç‰¹å¾ç‹¬ç«‹æ€§å‡è®¾ä¸æˆç«‹çš„æƒ…å†µä¸‹ä»èƒ½è¡¨ç°è‰¯å¥½ï¼Ÿ
2. åœ¨ä»€ä¹ˆæƒ…å†µä¸‹åº”è¯¥é€‰æ‹©æœ´ç´ è´å¶æ–¯è€Œéå…¶ä»–åˆ†ç±»ç®—æ³•ï¼Ÿ
3. å¦‚ä½•æ”¹è¿›æœ´ç´ è´å¶æ–¯ä»¥å¤„ç†ç‰¹å¾é—´çš„ä¾èµ–å…³ç³»ï¼Ÿ

<BackToPath />

<div class="practice-link">
  <a href="/projects/classification.html" class="button">å‰å¾€å®è·µé¡¹ç›®</a>
</div> 