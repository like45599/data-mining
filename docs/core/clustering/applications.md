# èšç±»å®é™…åº”ç”¨æ¡ˆä¾‹

<div class="knowledge-card">
  <div class="knowledge-card__title">
    <span class="icon">ğŸ“š</span>æœ¬èŠ‚è¦ç‚¹
  </div>
  <div class="knowledge-card__content">
    <ul>
      <li>äº†è§£èšç±»åˆ†æåœ¨ä¸åŒé¢†åŸŸçš„å®é™…åº”ç”¨</li>
      <li>æŒæ¡ä»ä¸šåŠ¡é—®é¢˜åˆ°èšç±»æ–¹æ¡ˆçš„è½¬åŒ–æ–¹æ³•</li>
      <li>å­¦ä¹ èšç±»ç»“æœçš„è§£é‡Šå’Œä¸šåŠ¡ä»·å€¼æŒ–æ˜</li>
      <li>ç†è§£èšç±»åˆ†æåœ¨å®é™…åº”ç”¨ä¸­çš„æŒ‘æˆ˜å’Œè§£å†³æ–¹æ¡ˆ</li>
    </ul>
  </div>
</div>

## å®¢æˆ·åˆ†ç¾¤æ¡ˆä¾‹

å®¢æˆ·åˆ†ç¾¤æ˜¯èšç±»åˆ†ææœ€å¸¸è§çš„åº”ç”¨ä¹‹ä¸€ï¼Œé€šè¿‡å°†å®¢æˆ·åˆ’åˆ†ä¸ºä¸åŒç¾¤ä½“ï¼Œä¼ä¸šå¯ä»¥åˆ¶å®šé’ˆå¯¹æ€§çš„è¥é”€ç­–ç•¥ã€‚

### ä¸šåŠ¡èƒŒæ™¯

æŸç”µå•†å¹³å°å¸Œæœ›é€šè¿‡åˆ†æç”¨æˆ·è¡Œä¸ºæ•°æ®ï¼Œå°†ç”¨æˆ·åˆ’åˆ†ä¸ºä¸åŒç¾¤ä½“ï¼Œä»¥ä¾¿åˆ¶å®šå·®å¼‚åŒ–çš„è¥é”€ç­–ç•¥å’Œä¸ªæ€§åŒ–æ¨èã€‚

### æ•°æ®å‡†å¤‡

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

# åŠ è½½æ•°æ®
df = pd.read_csv('customer_data.csv')

# æŸ¥çœ‹æ•°æ®
print(df.head())
print(df.info())

# ç‰¹å¾é€‰æ‹©
features = ['recency', 'frequency', 'monetary', 'tenure', 'age']
X = df[features]

# å¤„ç†ç¼ºå¤±å€¼
X = X.fillna(X.mean())

# ç‰¹å¾ç¼©æ”¾
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# æŸ¥çœ‹ç‰¹å¾ç›¸å…³æ€§
plt.figure(figsize=(10, 8))
sns.heatmap(df[features].corr(), annot=True, cmap='coolwarm')
plt.title('ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ')
plt.show()
```

  </div>
</div>

### ç¡®å®šæœ€ä½³ç°‡æ•°

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
from sklearn.metrics import silhouette_score

# ä½¿ç”¨è‚˜éƒ¨æ³•åˆ™ç¡®å®šæœ€ä½³Kå€¼
wcss = []
silhouette_scores = []
K_range = range(2, 11)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)
    
    # è®¡ç®—è½®å»“ç³»æ•°
    labels = kmeans.labels_
    silhouette_scores.append(silhouette_score(X_scaled, labels))

# å¯è§†åŒ–è‚˜éƒ¨æ³•åˆ™
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(K_range, wcss, 'o-')
plt.xlabel('ç°‡æ•°é‡ (K)')
plt.ylabel('WCSS')
plt.title('è‚˜éƒ¨æ³•åˆ™')
plt.grid(True)

# å¯è§†åŒ–è½®å»“ç³»æ•°
plt.subplot(1, 2, 2)
plt.plot(K_range, silhouette_scores, 'o-')
plt.xlabel('ç°‡æ•°é‡ (K)')
plt.ylabel('è½®å»“ç³»æ•°')
plt.title('è½®å»“ç³»æ•°æ³•')
plt.grid(True)

plt.tight_layout()
plt.show()

# é€‰æ‹©æœ€ä½³Kå€¼
best_k = 4  # æ ¹æ®ä¸Šè¿°åˆ†æç¡®å®š
```

  </div>
</div>

### èšç±»åˆ†æ

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
# ä½¿ç”¨æœ€ä½³Kå€¼è¿›è¡Œèšç±»
kmeans = KMeans(n_clusters=best_k, random_state=42)
df['cluster'] = kmeans.fit_predict(X_scaled)

# é™ç»´å¯è§†åŒ–
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# å¯è§†åŒ–èšç±»ç»“æœ
plt.figure(figsize=(10, 8))
scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['cluster'], cmap='viridis', s=50, alpha=0.8)
plt.title('å®¢æˆ·åˆ†ç¾¤ç»“æœ (PCAé™ç»´)')
plt.xlabel('ä¸»æˆåˆ†1')
plt.ylabel('ä¸»æˆåˆ†2')
plt.colorbar(scatter, label='ç°‡æ ‡ç­¾')
plt.grid(True)
plt.show()

# åˆ†æå„ç°‡çš„ç‰¹å¾
cluster_centers = pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_), columns=features)
print("ç°‡ä¸­å¿ƒ:")
print(cluster_centers)

# å„ç°‡çš„ç»Ÿè®¡æè¿°
for i in range(best_k):
    print(f"\nç°‡ {i} çš„ç»Ÿè®¡æè¿°:")
    print(df[df['cluster'] == i][features].describe())
```

  </div>
</div>

### ä¸šåŠ¡è§£é‡Šä¸åº”ç”¨

æ ¹æ®èšç±»ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥å°†å®¢æˆ·åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªç¾¤ä½“ï¼š

<div class="table-container">
  <table>
    <thead>
      <tr>
        <th>å®¢æˆ·ç¾¤ä½“</th>
        <th>ç‰¹å¾æè¿°</th>
        <th>è¥é”€ç­–ç•¥</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>é«˜ä»·å€¼å¿ è¯šå®¢æˆ·</td>
        <td>
          - è´­ä¹°é¢‘ç‡é«˜<br>
          - æ¶ˆè´¹é‡‘é¢å¤§<br>
          - æœ€è¿‘æœ‰è´­ä¹°<br>
          - å®¢æˆ·å¹´é¾„è¾ƒé•¿
        </td>
        <td>
          - VIPä¼šå‘˜è®¡åˆ’<br>
          - ä¸“å±ä¼˜æƒ <br>
          - é«˜ç«¯äº§å“æ¨è<br>
          - å¿ è¯šåº¦å¥–åŠ±
        </td>
      </tr>
      <tr>
        <td>æ½œåŠ›å®¢æˆ·</td>
        <td>
          - è´­ä¹°é¢‘ç‡ä¸­ç­‰<br>
          - æ¶ˆè´¹é‡‘é¢ä¸­ç­‰<br>
          - æœ€è¿‘æœ‰è´­ä¹°<br>
          - å®¢æˆ·å¹´é¾„è¾ƒçŸ­
        </td>
        <td>
          - ä¼šå‘˜å‡çº§æ¿€åŠ±<br>
          - äº¤å‰é”€å”®<br>
          - ä¸ªæ€§åŒ–æ¨è<br>
          - é™æ—¶ä¼˜æƒ 
        </td>
      </tr>
      <tr>
        <td>ä¼‘çœ å®¢æˆ·</td>
        <td>
          - è´­ä¹°é¢‘ç‡ä½<br>
          - æ¶ˆè´¹é‡‘é¢ä¸­ç­‰<br>
          - æœ€è¿‘æ— è´­ä¹°<br>
          - å®¢æˆ·å¹´é¾„è¾ƒé•¿
        </td>
        <td>
          - é‡æ–°æ¿€æ´»æ´»åŠ¨<br>
          - ç‰¹åˆ«æŠ˜æ‰£<br>
          - æ–°äº§å“é€šçŸ¥<br>
          - è°ƒæŸ¥åé¦ˆ
        </td>
      </tr>
      <tr>
        <td>æ–°å®¢æˆ·</td>
        <td>
          - è´­ä¹°é¢‘ç‡ä½<br>
          - æ¶ˆè´¹é‡‘é¢ä½<br>
          - æœ€è¿‘æœ‰è´­ä¹°<br>
          - å®¢æˆ·å¹´é¾„çŸ­
        </td>
        <td>
          - æ¬¢è¿ç¤¼åŒ…<br>
          - å…¥é—¨çº§äº§å“æ¨è<br>
          - è‡ªåŠ¨åŒ–è¥é”€
        </td>
      </tr>
    </tbody>
  </table>
</div>

## å¼‚å¸¸æ£€æµ‹æ¡ˆä¾‹

èšç±»åˆ†æå¯ä»¥ç”¨äºè¯†åˆ«æ•°æ®ä¸­çš„å¼‚å¸¸ç‚¹ï¼Œè¿™åœ¨æ¬ºè¯ˆæ£€æµ‹ã€ç½‘ç»œå®‰å…¨ç­‰é¢†åŸŸéå¸¸æœ‰ç”¨ã€‚

### ä¸šåŠ¡èƒŒæ™¯

æŸé“¶è¡Œéœ€è¦ä»å¤§é‡äº¤æ˜“æ•°æ®ä¸­è¯†åˆ«å¯èƒ½çš„æ¬ºè¯ˆäº¤æ˜“ã€‚

### æ•°æ®å‡†å¤‡ä¸èšç±»

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import DBSCAN
from sklearn.decomposition import PCA

# åŠ è½½äº¤æ˜“æ•°æ®
df = pd.read_csv('transactions.csv')

# ç‰¹å¾é€‰æ‹©
features = ['amount', 'time_since_last_transaction', 'distance_from_home', 'foreign_transaction', 'high_risk_merchant']
X = df[features]

# ç‰¹å¾ç¼©æ”¾
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ä½¿ç”¨DBSCANè¿›è¡Œèšç±»
dbscan = DBSCAN(eps=0.5, min_samples=5)
clusters = dbscan.fit_predict(X_scaled)

# å°†èšç±»ç»“æœæ·»åŠ åˆ°åŸå§‹æ•°æ®
df['cluster'] = clusters

# è¯†åˆ«å¼‚å¸¸ç‚¹ï¼ˆæ ‡ç­¾ä¸º-1çš„ç‚¹ï¼‰
outliers = df[df['cluster'] == -1]
print(f"æ£€æµ‹åˆ° {len(outliers)} ä¸ªå¼‚å¸¸äº¤æ˜“")

# é™ç»´å¯è§†åŒ–
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

plt.figure(figsize=(10, 8))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis', s=50, alpha=0.8)
plt.scatter(X_pca[clusters == -1, 0], X_pca[clusters == -1, 1], c='red', s=100, alpha=0.8, marker='X')
plt.title('äº¤æ˜“å¼‚å¸¸æ£€æµ‹')
plt.xlabel('ä¸»æˆåˆ†1')
plt.ylabel('ä¸»æˆåˆ†2')
plt.colorbar(label='ç°‡æ ‡ç­¾')
plt.show()

# åˆ†æå¼‚å¸¸äº¤æ˜“çš„ç‰¹å¾
print("å¼‚å¸¸äº¤æ˜“çš„ç‰¹å¾ç»Ÿè®¡:")
print(outliers[features].describe())
print("\næ­£å¸¸äº¤æ˜“çš„ç‰¹å¾ç»Ÿè®¡:")
print(df[df['cluster'] != -1][features].describe())
```

  </div>
</div>

### ä¸šåŠ¡å»ºè®®

åŸºäºå¼‚å¸¸æ£€æµ‹ç»“æœï¼Œå¯ä»¥æå‡ºä»¥ä¸‹å»ºè®®ï¼š

1. **å®æ—¶ç›‘æ§ç³»ç»Ÿ**ï¼šå°†èšç±»æ¨¡å‹é›†æˆåˆ°å®æ—¶äº¤æ˜“ç›‘æ§ç³»ç»Ÿä¸­
2. **é£é™©è¯„åˆ†**ï¼šä¸ºæ¯ç¬”äº¤æ˜“è®¡ç®—å¼‚å¸¸åˆ†æ•°ï¼Œè¶…è¿‡é˜ˆå€¼æ—¶è§¦å‘äººå·¥å®¡æ ¸
3. **åˆ†å±‚é˜²å¾¡**ï¼šç»“åˆè§„åˆ™å¼•æ“å’Œæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œæ„å»ºå¤šå±‚æ¬ºè¯ˆé˜²å¾¡ç³»ç»Ÿ
4. **æŒç»­æ›´æ–°**ï¼šå®šæœŸä½¿ç”¨æ–°æ•°æ®é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œé€‚åº”æ¬ºè¯ˆæ¨¡å¼çš„å˜åŒ–

## æ–‡æ¡£èšç±»æ¡ˆä¾‹

èšç±»åˆ†æå¯ä»¥ç”¨äºç»„ç»‡å’Œåˆ†ç±»å¤§é‡æ–‡æœ¬æ–‡æ¡£ï¼Œå¸®åŠ©ä¿¡æ¯æ£€ç´¢å’Œä¸»é¢˜å‘ç°ã€‚

### ä¸šåŠ¡èƒŒæ™¯

æŸæ–°é—»ç½‘ç«™éœ€è¦è‡ªåŠ¨å¯¹å¤§é‡æ–°é—»æ–‡ç« è¿›è¡Œåˆ†ç±»ï¼Œä»¥ä¾¿æ›´å¥½åœ°ç»„ç»‡å†…å®¹å’Œæ¨èç›¸å…³æ–‡ç« ã€‚

### æ–‡æœ¬é¢„å¤„ç†ä¸ç‰¹å¾æå–

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.decomposition import TruncatedSVD
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import re

# ä¸‹è½½å¿…è¦çš„NLTKèµ„æº
nltk.download('stopwords')
nltk.download('wordnet')

# åŠ è½½æ–°é—»æ•°æ®
df = pd.read_csv('news_articles.csv')

# æ–‡æœ¬é¢„å¤„ç†å‡½æ•°
def preprocess_text(text):
    # è½¬æ¢ä¸ºå°å†™
    text = text.lower()
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦å’Œæ•°å­—
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    # åˆ†è¯
    tokens = text.split()
    # ç§»é™¤åœç”¨è¯
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]
    # è¯å½¢è¿˜åŸ
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(word) for word in tokens]
    # é‡æ–°ç»„åˆä¸ºæ–‡æœ¬
    return ' '.join(tokens)

# åº”ç”¨é¢„å¤„ç†
df['processed_text'] = df['content'].apply(preprocess_text)

# ä½¿ç”¨TF-IDFæå–ç‰¹å¾
vectorizer = TfidfVectorizer(max_features=1000)
X = vectorizer.fit_transform(df['processed_text'])

# é™ç»´ä»¥ä¾¿å¯è§†åŒ–
svd = TruncatedSVD(n_components=2)
X_svd = svd.fit_transform(X)

# ç¡®å®šæœ€ä½³ç°‡æ•°
wcss = []
K_range = range(2, 11)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X)
    wcss.append(kmeans.inertia_)

# å¯è§†åŒ–è‚˜éƒ¨æ³•åˆ™
plt.figure(figsize=(10, 6))
plt.plot(K_range, wcss, 'o-')
plt.xlabel('ç°‡æ•°é‡ (K)')
plt.ylabel('WCSS')
plt.title('è‚˜éƒ¨æ³•åˆ™')
plt.grid(True)
plt.show()

# é€‰æ‹©æœ€ä½³Kå€¼
best_k = 5  # æ ¹æ®ä¸Šè¿°åˆ†æç¡®å®š
```

  </div>
</div>

### èšç±»åˆ†æä¸ä¸»é¢˜æå–

<div class="code-example">
  <div class="code-example__title">ä»£ç ç¤ºä¾‹</div>
  <div class="code-example__content">

```python
# ä½¿ç”¨æœ€ä½³Kå€¼è¿›è¡Œèšç±»
kmeans = KMeans(n_clusters=best_k, random_state=42)
df['cluster'] = kmeans.fit_predict(X)

# å¯è§†åŒ–èšç±»ç»“æœ
plt.figure(figsize=(10, 8))
scatter = plt.scatter(X_svd[:, 0], X_svd[:, 1], c=df['cluster'], cmap='viridis', s=50, alpha=0.8)
plt.title('æ–°é—»æ–‡ç« èšç±»ç»“æœ')
plt.xlabel('æˆåˆ†1')
plt.ylabel('æˆåˆ†2')
plt.colorbar(scatter, label='ç°‡æ ‡ç­¾')
plt.grid(True)
plt.show()

# æå–æ¯ä¸ªç°‡çš„å…³é”®è¯
feature_names = vectorizer.get_feature_names_out()
centroids = kmeans.cluster_centers_

for i in range(best_k):
    # è·å–ç°‡ä¸­å¿ƒçš„å‰10ä¸ªå…³é”®è¯
    top_indices = centroids[i].argsort()[-10:][::-1]
    top_keywords = [feature_names[idx] for idx in top_indices]
    
    print(f"ç°‡ {i} çš„å…³é”®è¯: {', '.join(top_keywords)}")
    
    # æ˜¾ç¤ºè¯¥ç°‡çš„ç¤ºä¾‹æ–‡ç« æ ‡é¢˜
    print(f"ç°‡ {i} çš„ç¤ºä¾‹æ–‡ç« :")
    for title in df[df['cluster'] == i]['title'].head(3):
        print(f"- {title}")
    print()
```

  </div>
</div>

### ä¸šåŠ¡åº”ç”¨

åŸºäºæ–‡æ¡£èšç±»ç»“æœï¼Œå¯ä»¥å®ç°ä»¥ä¸‹åº”ç”¨ï¼š

1. **è‡ªåŠ¨å†…å®¹åˆ†ç±»**ï¼šå°†æ–°æ–‡ç« è‡ªåŠ¨åˆ†é…åˆ°ç›¸åº”çš„ç±»åˆ«
2. **ç›¸å…³æ–‡ç« æ¨è**ï¼šä¸ºç”¨æˆ·æ¨èä¸å½“å‰é˜…è¯»æ–‡ç« åŒç±»çš„å…¶ä»–æ–‡ç« 
3. **ä¸»é¢˜å‘ç°**ï¼šè¯†åˆ«çƒ­é—¨è¯é¢˜å’Œæ–°å…´è¶‹åŠ¿
4. **å†…å®¹ç»„ç»‡**ï¼šä¼˜åŒ–ç½‘ç«™å¯¼èˆªå’Œå†…å®¹ç»“æ„

<div class="knowledge-card">
  <div class="knowledge-card__title">
    <span class="icon">âš ï¸</span>å¸¸è§è¯¯åŒº
  </div>
  <div class="knowledge-card__content">
    <ul>
      <li><strong>å¿½ç•¥ä¸šåŠ¡èƒŒæ™¯</strong>ï¼šèšç±»ç»“æœéœ€è¦ç»“åˆä¸šåŠ¡çŸ¥è¯†è§£é‡Šæ‰æœ‰æ„ä¹‰</li>
      <li><strong>è¿‡åº¦ä¾èµ–è‡ªåŠ¨åŒ–</strong>ï¼šèšç±»æ˜¯è¾…åŠ©å·¥å…·ï¼Œä¸åº”å®Œå…¨æ›¿ä»£äººå·¥åˆ¤æ–­</li>
      <li><strong>å¿½ç•¥æ•°æ®è´¨é‡</strong>ï¼šåƒåœ¾è¿›ï¼Œåƒåœ¾å‡ºï¼Œæ•°æ®è´¨é‡å¯¹èšç±»ç»“æœè‡³å…³é‡è¦</li>
      <li><strong>å¿½ç•¥æ¨¡å‹æ›´æ–°</strong>ï¼šå®¢æˆ·è¡Œä¸ºå’Œå¸‚åœºç¯å¢ƒä¼šå˜åŒ–ï¼Œèšç±»æ¨¡å‹éœ€è¦å®šæœŸæ›´æ–°</li>
    </ul>
  </div>
</div>

## å°ç»“ä¸æ€è€ƒ

èšç±»åˆ†æåœ¨å®¢æˆ·åˆ†ç¾¤ã€å¼‚å¸¸æ£€æµ‹å’Œæ–‡æ¡£ç»„ç»‡ç­‰å¤šä¸ªé¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ã€‚é€šè¿‡å°†æ•°æ®åˆ’åˆ†ä¸ºæœ‰æ„ä¹‰çš„ç¾¤ä½“ï¼Œä¼ä¸šå¯ä»¥è·å¾—å®è´µçš„ä¸šåŠ¡æ´å¯Ÿã€‚

### å…³é”®è¦ç‚¹å›é¡¾

- èšç±»åˆ†æå¯ä»¥å¸®åŠ©ä¼ä¸šå‘ç°æ•°æ®ä¸­çš„è‡ªç„¶åˆ†ç»„
- ä»ä¸šåŠ¡é—®é¢˜åˆ°èšç±»æ–¹æ¡ˆéœ€è¦åˆç†çš„ç‰¹å¾é€‰æ‹©å’Œé¢„å¤„ç†
- èšç±»ç»“æœçš„è§£é‡Šéœ€è¦ç»“åˆé¢†åŸŸçŸ¥è¯†
- èšç±»åˆ†æå¯ä»¥ä¸ºä¸ªæ€§åŒ–è¥é”€ã€é£é™©ç®¡ç†ç­‰æä¾›æ”¯æŒ

### æ€è€ƒé—®é¢˜

1. å¦‚ä½•å°†èšç±»ç»“æœè½¬åŒ–ä¸ºå¯æ“ä½œçš„ä¸šåŠ¡ç­–ç•¥ï¼Ÿ
2. åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¦‚ä½•è¯„ä¼°èšç±»æ–¹æ¡ˆçš„ä¸šåŠ¡ä»·å€¼ï¼Ÿ
3. èšç±»åˆ†æå¦‚ä½•ä¸å…¶ä»–æ•°æ®æŒ–æ˜æŠ€æœ¯ç»“åˆä½¿ç”¨ï¼Ÿ

<div class="practice-link">
  <a href="/projects/clustering.html" class="button">å‰å¾€å®è·µé¡¹ç›®</a>
</div> 